{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T06:43:25.371851Z",
     "start_time": "2025-06-12T06:43:18.799226Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from sqlalchemy.testing.suite.test_reflection import metadata\n",
    "\n",
    "np.random.seed(42)\n",
    "with open('taji_1.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DATA Preprocessing",
   "id": "a7c03e103021f305"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:17:22.989496Z",
     "start_time": "2025-06-11T15:17:22.981473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract topics from context to new column\n",
    "def extract_topics(context_list):\n",
    "    topics = []\n",
    "    for context_item in context_list:\n",
    "        topics.append(context_item[0])\n",
    "    return topics\n",
    "\n",
    "df['topics'] = df['context'].apply(extract_topics)\n",
    "\n",
    "# Get all unique topics\n",
    "all_topics = set()\n",
    "for topics in df['topics']:\n",
    "    all_topics.update(topics)\n",
    "\n",
    "print(f\"Total unique topics: {len(all_topics)}\")\n"
   ],
   "id": "e2e28dfddef92f58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique topics: 388\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:17:31.823318Z",
     "start_time": "2025-06-11T15:17:31.818266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topic_to_samples = defaultdict(list)\n",
    "for idx, topics in enumerate(df['topics']):\n",
    "    for topic in topics:\n",
    "        topic_to_samples[topic].append(idx)"
   ],
   "id": "829467fd97a512b7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:17:40.180791Z",
     "start_time": "2025-06-11T15:17:40.145741Z"
    }
   },
   "cell_type": "code",
   "source": "topic_to_samples",
   "id": "64d7a3d5fb5e7534",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'۱۳ دلیل برای اینکه ': [0, 1, 2, 256, 257, 258],\n",
       "             'هانا بیکر ': [0, 1, 2, 510, 511],\n",
       "             'سامورایی ': [3, 4],\n",
       "             'سایتو دوسان ': [3, 4],\n",
       "             'سوپرتاکس ': [5, 6, 246, 247, 248],\n",
       "             'نینتندو ': [5, 6, 236, 237, 242],\n",
       "             'مالک سیدیبه ': [7, 8, 9],\n",
       "             'شیر طلایی ': [7, 8, 9, 241],\n",
       "             'مسابقه آواز یوروویژن ۲۰۱۹ ': [10],\n",
       "             'مسابقه آواز یوروویژن ۲۰۱۸ ': [10],\n",
       "             'نامه فرهنگستان ': [11, 12, 13, 14, 15, 436],\n",
       "             'سردبیر ': [11, 12, 13, 14, 15],\n",
       "             'خاطرات بریجت جونز (فیلم) ': [16, 17, 18, 19],\n",
       "             'جما جونز ': [16, 17, 18, 19],\n",
       "             'لامپ نئون ': [20, 21, 22, 23],\n",
       "             'جیوه ': [20, 21, 22, 23, 225, 226, 227, 228, 433, 434, 455],\n",
       "             'زابیواکا (برنامه تلویزیونی) ': [24, 25, 26, 27, 28, 29, 30, 31],\n",
       "             'جام جهانی فوتبال ۲۰۱۸ ': [24, 25, 26, 27, 28, 29, 30, 31],\n",
       "             'استفانی مک\\u200cمن ': [32, 33],\n",
       "             'دبلیودبلیوئی ': [32, 33],\n",
       "             'نیمه ماه مارس (فیلم) ': [34, 35, 254, 255, 257, 258],\n",
       "             'مریسا تومی ': [34, 35],\n",
       "             'چیکووا ': [36, 37, 38, 39, 437],\n",
       "             'چیراشی\\u200cزوشی ': [36, 37, 38, 39, 289],\n",
       "             'باشگاه فوتبال اوراوا رد دیاموندز ': [40, 41, 42, 43],\n",
       "             'لیگ قهرمانان آسیا ': [40, 41, 42, 43],\n",
       "             'یخ\\u200cزده ۲ ': [44, 48],\n",
       "             'فهرست فیلم\\u200cهای استودیوی انیمیشن والت دیزنی ': [44, 48],\n",
       "             'فرانسیسکو خنتو ': [45, 46, 47],\n",
       "             'تیم ملی فوتبال اسپانیا ': [45, 46, 47],\n",
       "             'حیات (فیلم ۲۰۱۷) ': [49, 50, 51, 52, 53, 54],\n",
       "             'جیک جیلنهال ': [49, 50, 51, 52, 53, 54, 260],\n",
       "             'هواوی آنر ۴سی ': [55, 56, 57],\n",
       "             'هواوی ': [55, 56, 57, 235],\n",
       "             'اصلاح کاتالیزوری ': [58],\n",
       "             'محصول جانبی ': [58],\n",
       "             'سوغات اصفهان ': [59, 63],\n",
       "             'میناکاری ': [59, 63],\n",
       "             'بازی\\u200cهای گرسنگی: زاغ مقلد – بخش ۲ ': [60],\n",
       "             'جاش هاچرسون ': [60, 238],\n",
       "             'فیلیپ تورتون ': [61, 62, 64, 65, 238, 260],\n",
       "             'روآن (فرانسه) ': [61, 62, 64, 65],\n",
       "             'نیکوتین ': [66, 67, 68, 69],\n",
       "             'سیب\\u200cزمینی ': [66, 67, 68, 69],\n",
       "             'زن زن است ': [70, 259],\n",
       "             'فیلم موزیکال ': [70],\n",
       "             'فرانک شیرن ': [71, 72],\n",
       "             'جیمی هوفا ': [71, 72],\n",
       "             'دوم (بازی ویدئویی ۲۰۱۶) ': [73, 74, 75, 76, 77, 78, 79],\n",
       "             'بتزدا سافت\\u200cورکز ': [73, 74, 75, 76, 77, 78, 79],\n",
       "             'سوخته (فیلم) ': [80],\n",
       "             'اما تامپسون ': [80],\n",
       "             'عشق نفسانیت صمیمیت: بهترین آهنگ\\u200cها ': [81],\n",
       "             'بیلی جین ': [81, 213, 214, 545],\n",
       "             'ناهار عریان (فیلم) ': [82, 83],\n",
       "             'روی شایدر ': [82, 83],\n",
       "             'آئورورا ': [84, 85],\n",
       "             'لومینیتسا گئورگیو ': [84, 85],\n",
       "             'جنگ ستارگان: قسمت دوم – حمله کلون\\u200cها ': [86, 87],\n",
       "             'فرانک اوز ': [86, 87],\n",
       "             'آلیس در شهرها ': [88,\n",
       "              89,\n",
       "              90,\n",
       "              250,\n",
       "              251,\n",
       "              252,\n",
       "              253,\n",
       "              254,\n",
       "              255,\n",
       "              256,\n",
       "              259],\n",
       "             'پاریس، تگزاس (فیلم) ': [88, 89, 90],\n",
       "             'ناپروکسن/اس\\u200cامپرازول ': [91],\n",
       "             'آرتروز ': [91],\n",
       "             'جنگ جهانی دوم ': [92, 93, 94, 95, 96, 97, 98],\n",
       "             'خانه آنه فرانک ': [92, 93, 94, 95, 96, 97, 98],\n",
       "             'صندوق قربانیان بزهکاری ': [99],\n",
       "             'غرامت ': [99],\n",
       "             'پودر سنگ ': [100, 101, 102],\n",
       "             'سنگ ': [100, 101, 102],\n",
       "             'تیم ملی فوتبال سوئیس ': [103, 104, 442],\n",
       "             'جام جهانی فوتبال ۲۰۰۶ ': [103, 104],\n",
       "             'لیگ عدالت (فیلم) ': [105, 106, 107, 108, 109, 162, 163, 164],\n",
       "             'کیران هایندز ': [105, 106, 107, 108, 109],\n",
       "             'پامچال شب ': [110],\n",
       "             'آمریکای شمالی ': [110],\n",
       "             'ابونعیم اصفهانی ': [111],\n",
       "             'دانشمند ': [111],\n",
       "             'سربداران (مجموعه تلویزیونی) ': [112,\n",
       "              113,\n",
       "              114,\n",
       "              115,\n",
       "              116,\n",
       "              117,\n",
       "              118,\n",
       "              119,\n",
       "              120,\n",
       "              121,\n",
       "              122],\n",
       "             'استودیو بل ': [112,\n",
       "              113,\n",
       "              114,\n",
       "              115,\n",
       "              116,\n",
       "              117,\n",
       "              118,\n",
       "              119,\n",
       "              120,\n",
       "              121,\n",
       "              122],\n",
       "             'مارشال\\u200cهای آمریکایی (فیلم) ': [123, 124, 125],\n",
       "             'دانیال روبوک ': [123, 124, 125],\n",
       "             'محمد ظاهرشاه ': [126, 127, 128, 129, 159, 435],\n",
       "             'سد سرده بند ': [126, 127, 128, 129],\n",
       "             'کشتن (فیلم ۱۹۵۶) ': [130, 131],\n",
       "             'مترو گلدوین مایر ': [130, 131],\n",
       "             'اگر سنگ از آسمان ببارد ': [132,\n",
       "              133,\n",
       "              134,\n",
       "              135,\n",
       "              136,\n",
       "              137,\n",
       "              138,\n",
       "              139],\n",
       "             'جشنواره فیلم کن ۲۰۱۶ ': [132, 133, 134, 135, 136, 137, 138, 139],\n",
       "             'کوچه کابوس (فیلم ۲۰۲۱) ': [140, 141, 142, 143],\n",
       "             'رونی مارا ': [140, 141, 142, 143],\n",
       "             'بال\\u200cلاکی ژاپنی ': [144, 444, 445],\n",
       "             'گنجشک\\u200cسانان ': [144],\n",
       "             'فرایند پواسون ': [145, 146],\n",
       "             'فرایند برنولی ': [145, 146],\n",
       "             'هل این ا سل (۲۰۱۶) ': [147, 148],\n",
       "             'کشتی کج ': [147, 148],\n",
       "             'تریپل اکس (فیلم ۲۰۰۲) ': [149, 150],\n",
       "             'ایو (رپر) ': [149, 150, 156, 157, 158],\n",
       "             'زانکلین ': [151],\n",
       "             'میوسن ': [151],\n",
       "             'ماشین پلیس (فیلم ۲۰۱۵) ': [152, 153],\n",
       "             'استخراج (فیلم ۲۰۱۵) ': [152, 153, 154, 155],\n",
       "             'استیون سی میلر ': [154, 155, 156, 157, 158],\n",
       "             'عبدالله جوادی آملی ': [159, 234],\n",
       "             'آخرین شکارچی جادوگر ': [160, 161, 193],\n",
       "             'مایکل کین ': [160, 161, 193],\n",
       "             'گل گدوت ': [162, 163, 164],\n",
       "             'دنیای مرا باشکوه می\\u200cکنی ': [165],\n",
       "             'شکست\\u200cناپذیر (آلبوم) ': [165],\n",
       "             'پرومتئوس': [166, 167, 250, 251, 252, 253],\n",
       "             'بیگانه ': [166, 167],\n",
       "             'قورباغه ': [168, 169, 170, 171, 445],\n",
       "             'مارمولک ': [168, 169, 170, 171, 444],\n",
       "             'بلوفیش (نرم\\u200cافزار) ': [172, 173, 174],\n",
       "             'والا (زبان برنامه\\u200cنویسی) ': [172, 173, 174],\n",
       "             'حسین پاینده ': [175, 176, 177, 178, 234, 450],\n",
       "             'هوشنگ گلشیری ': [175, 176, 177, 178, 436],\n",
       "             'پل کلبنیکوف ': [179, 180, 181],\n",
       "             'فوربز ': [179, 180, 181],\n",
       "             'انتس\\u200cها ': [182, 183, 184, 185, 186, 239],\n",
       "             'نگاناسان\\u200cها ': [182, 183, 184, 185, 186],\n",
       "             'پیتر ولر ': [187, 188],\n",
       "             'ویلیام اس باروز ': [187, 188],\n",
       "             'فرانسواز دورلیاک ': [189, 190],\n",
       "             'بن\\u200cبست (فیلم ۱۹۶۶) ': [189, 190],\n",
       "             'سانتافه دو نوومکزیکو ': [191, 192],\n",
       "             'آپاچی (قبیله) ': [191, 192, 239],\n",
       "             'نینجا گایدن (بازی آرکید) ': [194, 195, 196, 244, 245],\n",
       "             'تکمو ': [194, 195, 196, 235, 236, 237, 243],\n",
       "             'برج چیس شیکاگو ': [197, 198],\n",
       "             'آسمان\\u200cخراش ': [197, 198],\n",
       "             'زن جوان آتیه\\u200cدار ': [199],\n",
       "             'فیلم دلهره\\u200cآور ': [199],\n",
       "             'شکار جانور شگفت\\u200cانگیز ': [200, 201, 202, 203, 204],\n",
       "             'هنری هالیدی ': [200, 201, 202, 203, 204],\n",
       "             'آبله\\u200cمیمون ': [205, 206, 482],\n",
       "             'تب ': [205, 206, 479, 480, 481],\n",
       "             'سورا ال\\u200cتی\\u200cدی ': [207, 208, 209, 242, 243],\n",
       "             'برادران سوپر اسمش ': [207, 208, 209],\n",
       "             'کیران دسای ': [210, 211, 212, 453],\n",
       "             'جایزه ادبی من بوکر ': [210, 211, 212, 240],\n",
       "             'اپیک رکوردز ': [213, 214],\n",
       "             'تجربیات سریالی لین ': [215, 216, 217],\n",
       "             'یوشی\\u200cتوشی آبه ': [215, 216, 217],\n",
       "             'اقوام اولیه کانادا ': [218],\n",
       "             'اینوئیت ': [218],\n",
       "             'ونسا مارانو ': [219, 220],\n",
       "             'جوایز گلدن گلوب ': [219, 220, 240, 241, 381],\n",
       "             'سوار کماندار ': [221, 222, 223, 224],\n",
       "             'مغول ': [221, 222, 223, 224],\n",
       "             'فلزات نجیب ': [225, 226, 227, 228, 448, 456, 457, 458],\n",
       "             'سلستیا ': [229],\n",
       "             'اوپن\\u200cجی\\u200cال ': [229],\n",
       "             'ایس کمبت ۷: آسمان\\u200cهای ناشناخته ': [230, 231, 247, 248, 249],\n",
       "             'اکس\\u200cباکس وان ': [230, 231],\n",
       "             'ندای وظیفه ': [232, 233, 244, 245, 246, 249],\n",
       "             'اینفینیتی وارد ': [232, 233],\n",
       "             'پوغوس آفیان ': [261, 262, 476, 477],\n",
       "             'جوزپه وردی ': [261, 262, 476, 477],\n",
       "             'اساسینز کرید: سرکش ': [263, 478],\n",
       "             'جهان باز ': [263, 478],\n",
       "             'خلیفه بن حمد بن خلیفه آل ثانی ': [264, 265, 266, 267],\n",
       "             'آل ثانی ': [264, 265, 266, 267],\n",
       "             'خانه بردباری ': [268, 269, 270, 271, 272, 273],\n",
       "             'حفصیه حرزی ': [268, 269, 270, 271, 272, 273],\n",
       "             'انجیل مرقس ': [274],\n",
       "             'انجیل متی ': [274],\n",
       "             'لوک اسکای\\u200cواکر ': [275,\n",
       "              276,\n",
       "              277,\n",
       "              278,\n",
       "              279,\n",
       "              280,\n",
       "              483,\n",
       "              484,\n",
       "              485,\n",
       "              486,\n",
       "              487,\n",
       "              488],\n",
       "             'جرج لوکاس ': [275, 276, 277, 278, 279, 280],\n",
       "             'ایرج صغیری ': [281],\n",
       "             'داریوش ارجمند ': [281],\n",
       "             'پشه ': [282, 283],\n",
       "             'فیلاریاز ': [282, 283],\n",
       "             'جوی لورن آدامز ': [284, 285, 286, 287],\n",
       "             'سر مخروطی\\u200cها ': [284, 285, 286, 287],\n",
       "             'زوسویی ': [288, 289, 437],\n",
       "             'نابه\\u200cمونو ': [288],\n",
       "             'کامران میرزا (بابری) ': [290],\n",
       "             'بابر ': [290],\n",
       "             'پرونده\\u200cهای ایکس ': [291, 292],\n",
       "             'شرکت پخش همگانی فاکس ': [291, 292],\n",
       "             'جنگ بزرگ شمالی ': [293, 294, 295],\n",
       "             'پتر یکم ': [293, 294, 295, 446, 447],\n",
       "             'پیروز یکم ': [296, 297, 435, 501],\n",
       "             'کیداریان ': [296, 297],\n",
       "             '۵۰ قرار اول ': [298],\n",
       "             'پیتر سگال ': [298],\n",
       "             'ترا (ماهواره) ': [299, 300, 301],\n",
       "             'مدار خورشیدآهنگ ': [299, 300, 301],\n",
       "             'کرایسیس ۲ ': [302, 303],\n",
       "             'الکترونیک آرتس ': [302, 303],\n",
       "             'جاستین چنگ ': [304, 305, 306, 307],\n",
       "             'لس آنجلس تایمز ': [304, 305, 306, 307],\n",
       "             'متبارک با آتش ': [308],\n",
       "             'گاستون پائولس ': [308],\n",
       "             'خورشید همچنان می\\u200cدمد ': [309, 310, 311, 312],\n",
       "             'ارنست همینگوی ': [309, 310, 311, 312],\n",
       "             'تیم ملی فوتبال بلغارستان ': [313, 314],\n",
       "             'تیم ملی فوتبال آلمان ': [313, 314, 442, 499],\n",
       "             'رشک قضیب ': [315, 316],\n",
       "             'هلن سیکسو ': [315, 316],\n",
       "             'برج سبز ': [317],\n",
       "             'آن بولین ': [317],\n",
       "             'اداره (فصل ۳) ': [318, 319, 320],\n",
       "             'اداره (مجموعه تلویزیونی بریتانیایی) ': [318, 319, 320],\n",
       "             'میشل مایور ': [321],\n",
       "             'جایزه کیوتو ': [321],\n",
       "             'کمون (فیلم) ': [322],\n",
       "             'شصت و ششمین جشنواره بین\\u200cالمللی فیلم برلین ': [322],\n",
       "             'فرودگاه بین\\u200cالمللی قاسم سلیمانی ': [323, 426, 427, 429],\n",
       "             'هواپیمایی ایران ایرتور ': [323, 430, 431, 432],\n",
       "             'مارک وب ': [324],\n",
       "             'با استعداد ': [324],\n",
       "             'قهرمانان گریه نمی\\u200cکنند (فیلم ۱۹۸۶) ': [325, 326],\n",
       "             'فردایی بهتر ': [325, 326],\n",
       "             'پلی\\u200cاستیشن ۴ ': [327],\n",
       "             'مایکروسافت ویندوز ': [327],\n",
       "             'آرتی شاو: زمان چیزی است که به\\u200cدست آورده\\u200cای ': [328,\n",
       "              329,\n",
       "              330,\n",
       "              440],\n",
       "             'بی\\u200cخانمانی در آمریکا ': [328, 329, 330, 441],\n",
       "             'چین\\u200cخوردگی در زمان ': [331, 332, 333],\n",
       "             'زک گالیفیناکیس ': [331, 332, 333],\n",
       "             'اکبر عبدی ': [334, 428],\n",
       "             'فرشاد پیوس ': [334],\n",
       "             'نوشاد عالمیان ': [335, 336, 337, 338, 339, 340, 341],\n",
       "             'نیما عالمیان ': [335, 336, 337, 338, 339, 340, 341],\n",
       "             'نماز جمعه در ایران ': [342],\n",
       "             'بیرجند ': [342],\n",
       "             'فریبا وفی ': [343],\n",
       "             'نویسنده ': [343],\n",
       "             'پلی\\u200cاستیشن همراه ': [344],\n",
       "             'رابیدها ': [344, 438, 439],\n",
       "             'آنتونیو دی نولی ': [345, 346],\n",
       "             'آفونسوی پنجم ': [345, 346],\n",
       "             'امپراتوری برزیل ': [347],\n",
       "             'پدرو آلوارز کابرال ': [347],\n",
       "             'هواپیمایی ماهان ': [348, 429, 430, 431, 432],\n",
       "             'فرودگاه بجنورد ': [348, 426, 427],\n",
       "             'تقاطع (مستند) ': [349, 350, 351, 352, 353],\n",
       "             'رضا فرهمند ': [349, 350, 351, 352, 353, 428],\n",
       "             'سعید بشیرتاش ': [354],\n",
       "             'تامی حامی\\u200cفر ': [354],\n",
       "             'آرایه\\u200cشناسی (زیست\\u200cشناسی) ': [355],\n",
       "             'کارل لینه ': [355],\n",
       "             'آشیانه ': [356],\n",
       "             'گونه (زیست\\u200cشناسی) ': [356],\n",
       "             'سازمان ملل متحد ': [357],\n",
       "             'کودتا ': [357],\n",
       "             'کیم یونگ-کوانگ (بازیگر) ': [358, 359, 360, 361],\n",
       "             'پینوکیو (مجموعه تلویزیونی ۲۰۱۴) ': [358, 359, 360, 361],\n",
       "             'اکسایش حرارتی ': [362, 363, 364, 365],\n",
       "             'ویفر (الکترونیک) ': [362, 363, 364, 365],\n",
       "             'علی لقمانی ': [366, 367, 368, 369],\n",
       "             'عروس آتش ': [366, 367, 368, 369],\n",
       "             'آدامانتیوس کورائیس ': [370, 371],\n",
       "             'دانته آلیگیری ': [370, 371],\n",
       "             'محمد سبزواری ': [372, 373],\n",
       "             'صادقی\\u200cبیک افشار ': [372, 373],\n",
       "             'فهرست کشورهای دارنده جنگ\\u200cافزار هسته\\u200cای ': [374, 375],\n",
       "             'آفریقای جنوبی ': [374, 375],\n",
       "             'جوکیو (دوره ادو) ': [376, 377, 378],\n",
       "             'گن\\u200cروکو ': [376, 377, 378],\n",
       "             'میشائیل شوماخر ': [379, 380],\n",
       "             'اسکودریا فراری ': [379, 380],\n",
       "             'جوایز اسکار ': [381],\n",
       "             'تهدید سه\\u200cگانه ': [382, 383],\n",
       "             'ایکو اویس ': [382, 383],\n",
       "             'آهن ': [384, 433, 434, 448, 454, 517],\n",
       "             'موتور الکتریکی ': [384],\n",
       "             'پنج عصر ': [385, 386, 387],\n",
       "             'تخته\\u200cسیاه (فیلم) ': [385, 386, 387],\n",
       "             'انقراض هولوسن ': [388, 389],\n",
       "             'شیر ایرانی ': [388, 389],\n",
       "             'ولاک ': [390],\n",
       "             'آلبانیایی\\u200cها ': [390],\n",
       "             'عصر جدید (فیلم ۱۹۳۶) ': [391, 392],\n",
       "             'چارلی چاپلین ': [391, 392],\n",
       "             'مارلو (فیلم آینده) ': [393, 394],\n",
       "             'آدواله آکینویه آگباجه ': [393, 394],\n",
       "             'شهر گمشده زی (فیلم) ': [395, 396, 397],\n",
       "             'تام هالند ': [395, 396, 397],\n",
       "             'روزی روزگاری در مکزیک ': [398],\n",
       "             'ژولیو اسکار مچوسو ': [398],\n",
       "             'سندرم زولینگر-الیسون ': [399, 400, 401],\n",
       "             'لوزالمعده ': [399, 400, 401],\n",
       "             'کم (آلبوم دیوید بویی) ': [402, 403],\n",
       "             'ایگی پاپ ': [402, 403],\n",
       "             'منتهای حد کمال ': [404, 405, 406],\n",
       "             'رودساید اترکشنز ': [404, 405, 406],\n",
       "             'برای اینکه (فیلم) ': [407, 408, 409, 410, 411],\n",
       "             'پرواز بر فراز آشیانه فاخته ': [407,\n",
       "              408,\n",
       "              409,\n",
       "              410,\n",
       "              411,\n",
       "              440,\n",
       "              441,\n",
       "              449],\n",
       "             'فرانک زاپا ': [412, 413],\n",
       "             'موسیقی راک ': [412, 413],\n",
       "             'آنتی\\u200cبیوتیک ': [414, 415],\n",
       "             'باکتری گرم-منفی ': [414, 415],\n",
       "             'آلکان ': [416, 417],\n",
       "             'روغن ': [416, 417],\n",
       "             'سایلنت هیل ۲ ': [418, 438, 439],\n",
       "             'پلی\\u200cاستیشن ۳ ': [418],\n",
       "             'فانک راک ': [419, 420],\n",
       "             'جیمز براون ': [419, 420],\n",
       "             'فینال\\u200cهای ان\\u200cبی\\u200cای ۱۹۹۴ ': [421,\n",
       "              422,\n",
       "              423,\n",
       "              424,\n",
       "              425],\n",
       "             'نیویورک نیکس ': [421, 422, 423, 424, 425],\n",
       "             'آب ': [443],\n",
       "             'محلول ': [443],\n",
       "             'امپراتوری روسیه ': [446, 447],\n",
       "             'پرستار رچد ': [449],\n",
       "             'محمد راسخ مهند ': [450],\n",
       "             'گرند ماستی ': [451, 452],\n",
       "             'مانجاری فاندیس ': [451, 452, 453],\n",
       "             'مس ': [454, 455, 456, 457, 458],\n",
       "             'لوئیجی ': [459],\n",
       "             'ماریو ': [459],\n",
       "             'لرد ولدمورت ': [460, 461, 462],\n",
       "             'جیکی رولینگ ': [460, 461, 462, 541, 542, 543, 544, 545],\n",
       "             'قوای قزاق ': [463,\n",
       "              464,\n",
       "              465,\n",
       "              466,\n",
       "              467,\n",
       "              468,\n",
       "              469,\n",
       "              470,\n",
       "              471,\n",
       "              472,\n",
       "              473],\n",
       "             'ناصرالدین\\u200cشاه ': [463,\n",
       "              464,\n",
       "              465,\n",
       "              466,\n",
       "              467,\n",
       "              468,\n",
       "              469,\n",
       "              470,\n",
       "              471,\n",
       "              472,\n",
       "              473],\n",
       "             'دیوید والاس ': [474, 475, 483, 484, 485],\n",
       "             'توبی فلندرسون ': [474, 475, 486, 487, 488],\n",
       "             'سپتیسمی ': [479, 480, 481, 482],\n",
       "             'داستان اسباب\\u200cبازی ۴ ': [489, 490],\n",
       "             'پیکسار ': [489, 490],\n",
       "             'ب\\u200cام\\u200cو ایکس۷ ': [491, 492],\n",
       "             'ب\\u200cام\\u200cو سری ۷ ': [491, 492],\n",
       "             'انجمن فیزیک ایران ': [493],\n",
       "             'محمود حسابی ': [493],\n",
       "             'قمری خانگی ': [494],\n",
       "             'آفریقای سیاه ': [494],\n",
       "             'افسون\\u200cنزده ': [495],\n",
       "             'مایا رودولف ': [495],\n",
       "             'جنکینز ': [496, 497],\n",
       "             'آپاچی سابورژن ': [496, 497],\n",
       "             'ایرتگ (ردیاب) ': [498],\n",
       "             'آیفون ۱۱ ': [498],\n",
       "             'باشگاه فوتبال منچستر سیتی ': [499],\n",
       "             'جیمز اتکینسون (خاورشناس) ': [500],\n",
       "             'کالج فورت ویلیام ': [500],\n",
       "             'علاءالدین حسین غوری ': [501],\n",
       "             'شرکت بهره\\u200cبرداری نفت و گاز مارون ': [502, 503, 504],\n",
       "             'میدان نفتی مارون ': [502, 503, 504],\n",
       "             'محسن کوهکن ': [505, 506],\n",
       "             'حوزه انتخابیه لنجان ': [505, 506],\n",
       "             'درون\\u200cکاشت مصنوعی ': [507],\n",
       "             'اسپرم ': [507],\n",
       "             'فار کرای پرایمال ': [508, 509],\n",
       "             'فار کرای ': [508, 509],\n",
       "             'آبین سور ': [510, 511],\n",
       "             'بنتونیت ': [512],\n",
       "             'طب سنتی ': [512],\n",
       "             'زنی پشت پنجره (فیلم ۲۰۲۱) ': [513],\n",
       "             'وایت راسل ': [513],\n",
       "             'اثر پروانه\\u200cای (فیلم) ': [514, 515, 516],\n",
       "             'ایمی اسمارت ': [514, 515, 516],\n",
       "             'فلز ': [517],\n",
       "             'سشات ': [518],\n",
       "             'ریاضیات ': [518],\n",
       "             'شب یلدا (فیلم) ': [519],\n",
       "             'کیومرث پوراحمد ': [519],\n",
       "             'جان اسلتری ': [520, 521],\n",
       "             'آندرداگ (فیلم ۲۰۰۷) ': [520, 521],\n",
       "             'بهترین زمان (فیلم) ': [522],\n",
       "             'روبین لایولی ': [522],\n",
       "             'دورنیه دو ۲۱۷ ': [523, 524, 525],\n",
       "             'دورنیه فلوکتسویک\\u200cورکه ': [523, 524, 525],\n",
       "             'نظریه عدالت ': [526],\n",
       "             'جان رالز ': [526],\n",
       "             'زبان اردو ': [527, 528],\n",
       "             'حمد ': [527, 528],\n",
       "             'این\\u200cاسلیو: اودیسه به سمت غرب ': [529, 530, 531],\n",
       "             'بندای نامکو انترتینمنت ': [529, 530, 531],\n",
       "             'سه نفر با یک کبریت ': [532],\n",
       "             'وارن ویلیام ': [532],\n",
       "             'پنجاه و نهمین دوره جوایز بفتا ': [533],\n",
       "             'فیلیپ سیمور هافمن ': [533],\n",
       "             'خامه ': [534],\n",
       "             'وگانیسم ': [534],\n",
       "             'نقشه\\u200cبردار موضوعی ': [535, 536, 537, 538],\n",
       "             'لندست ۴ ': [535, 536, 537, 538],\n",
       "             'گرگ هندی ': [539, 540],\n",
       "             'شبه\\u200cقاره هند ': [539, 540],\n",
       "             'هری پاتر و تالار اسرار (فیلم) ': [541, 542, 543, 544, 549],\n",
       "             'زبان ترکی استانبولی ': [546],\n",
       "             'هیوندای اصلان ': [546],\n",
       "             'کایوت در برابر اکمی ': [547, 548],\n",
       "             'برادران وارنر پیکچرز ': [547, 548, 549],\n",
       "             'مائدا ماتسو ': [550],\n",
       "             'کیوگوکو تاتسوکو ': [550],\n",
       "             'ساخت ساز سنتی در اردبیل ': [551],\n",
       "             'سه\\u200cتار ': [551]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:17:50.496839Z",
     "start_time": "2025-06-11T15:17:50.478516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select one sample per topic for training (to guarantee coverage)\n",
    "guaranteed_train_indices = set()\n",
    "for topic, sample_indices in topic_to_samples.items():\n",
    "    selected_idx = np.random.choice(sample_indices)\n",
    "    guaranteed_train_indices.add(selected_idx)\n",
    "\n",
    "print(f\"Guaranteed training samples: {len(guaranteed_train_indices)}\")"
   ],
   "id": "b7dd833373afebad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guaranteed training samples: 280\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:18:08.470941Z",
     "start_time": "2025-06-11T15:18:08.427463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remaining samples to allocate\n",
    "remaining_indices = set(range(len(df))) - guaranteed_train_indices\n",
    "remaining_indices = list(remaining_indices)\n",
    "\n",
    "additional_train_needed = 400 - len(guaranteed_train_indices)\n",
    "\n",
    "additional_train_indices = np.random.choice(\n",
    "    remaining_indices,\n",
    "    size=additional_train_needed,\n",
    "    replace=False\n",
    ")\n",
    "train_indices = list(guaranteed_train_indices) + list(additional_train_indices)\n",
    "all_indices = set(range(len(df)))\n",
    "test_indices = list(all_indices - set(train_indices))\n",
    "\n",
    "# Create train and test splits\n",
    "train_df = df.iloc[train_indices].reset_index(drop=True)\n",
    "test_df = df.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "# Remove the helper 'topics' column\n",
    "train_df = train_df.drop('topics', axis=1)\n",
    "test_df = test_df.drop('topics', axis=1)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ],
   "id": "408a2c6f39bece09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 400\n",
      "Test size: 152\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:19:52.026850Z",
     "start_time": "2025-06-11T15:19:51.738031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verify topic coverage in training\n",
    "train_topics = set()\n",
    "for _, row in train_df.iterrows():\n",
    "    for context_item in row['context']:\n",
    "        if len(context_item) > 0:\n",
    "            train_topics.add(context_item[0])\n",
    "\n",
    "print(f\"Topics in training set: {len(train_topics)}\")\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_json('train_data.json', orient='records', force_ascii=False, indent=2)\n",
    "test_df.to_json('test_data.json', orient='records', force_ascii=False, indent=2)"
   ],
   "id": "9353ddb9614a4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics in training set: 388\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RAG (PersianMHQA)",
   "id": "6cda43cb9d2503d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:44:02.919248Z",
     "start_time": "2025-06-14T04:43:57.670214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_json('train_data.json', orient='records', encoding='utf-8')\n",
    "test_df = pd.read_json('test_data.json', orient='records', encoding='utf-8')"
   ],
   "id": "9b7cfc02aedebecf",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare data for Retrieval",
   "id": "c6d714bdd3afea8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:44:10.641434Z",
     "start_time": "2025-06-14T04:44:10.030117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents: list[Document] = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    for doc in row['context']:\n",
    "        title = doc[0]\n",
    "        sentences = doc[1]\n",
    "        for index_sent, sentence in enumerate(sentences):\n",
    "            d = Document(\n",
    "                page_content=title + \" : \" +sentence,\n",
    "                metadata={\n",
    "                    'title': title,\n",
    "                    'index': index_sent,\n",
    "                    'question': row['question'],\n",
    "                    'answer': row['answer'],\n",
    "            })\n",
    "            documents.append(d)\n",
    "\n",
    "print(\"Length of documents: \", len(documents))"
   ],
   "id": "233b57b40731506e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of documents:  1316\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:44:14.291802Z",
     "start_time": "2025-06-14T04:44:13.650622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=64,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ],
   "id": "82c04c99506d11a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1316\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:56:51.627125Z",
     "start_time": "2025-06-14T04:56:13.588524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\", cache_folder=r\"Q:\\hf_models\", model_kwargs={\"local_files_only\": True})\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "semantic_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ],
   "id": "7aaa47381c6505d5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:56:55.592532Z",
     "start_time": "2025-06-14T04:56:55.580937Z"
    }
   },
   "cell_type": "code",
   "source": "vector_store.save_local(\"qwen3-0.6B-embs\")",
   "id": "e83c06965261ce09",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load local\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"Qwen/Qwen3-Embedding-0.6B\", cache_folder=r\"Q:\\hf_models\", model_kwargs={\"local_files_only\": True})\n",
    "vector_store = FAISS.load_local(\"qwen3-0.6B-embs\", embeddings=embedding_model)"
   ],
   "id": "244b8778b0db2409"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T05:00:16.992743Z",
     "start_time": "2025-06-14T05:00:16.875173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"You are a helpful assistant. Use the provided context to answer the user's question as accurately as possible in few words in Persian.\\nContext:\\n{context}\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "])"
   ],
   "id": "e6fe4618ff02356d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## API",
   "id": "5bf0e69c1aa76b8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Avval AI",
   "id": "8f351dc2d6bf5043"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T05:00:23.861129Z",
     "start_time": "2025-06-14T05:00:23.796193Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8,
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()"
   ],
   "id": "d77552fd2ffc1658"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T09:03:13.623288Z",
     "start_time": "2025-06-13T09:03:11.916418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(base_url=\"https://api.avalapis.ir/v1\", api_key=os.environ.get(\"AVVALAI\"), model=\"gemini-2.5-flash-preview-05-20\")"
   ],
   "id": "19c3de5b9a63f03a",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gemini",
   "id": "d941ad878ab41684"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass(\"Enter your API key: \")"
   ],
   "id": "95f6bf0a3616e571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", api_key=api_key)"
   ],
   "id": "cf552eec2b736756"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Semantic RAG",
   "id": "4668921aa9ba8ab7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T06:51:04.778477Z",
     "start_time": "2025-06-13T06:50:52.618237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "def generate_response(inputs):\n",
    "    # Format prompt with context and question\n",
    "    formatted_prompt = prompt.format_prompt(question=inputs[\"question\"], context=\"\\n\\n\".join(doc.page_content for doc in inputs[\"context\"])).to_messages()\n",
    "    result = llm(formatted_prompt)\n",
    "    parsed_result = output_parser.invoke(result)\n",
    "    return {\n",
    "        \"response\": parsed_result,\n",
    "        \"context\": inputs[\"context\"],\n",
    "    }\n",
    "# For this cell, everything is the same as the previous cell, except that we are using the semantic retriever instead of the sparse retriever.\n",
    "def get_context_dense(inputs, num_queries=3):\n",
    "    docs = semantic_retriever.get_relevant_documents(inputs[\"question\"], k=num_queries)\n",
    "    return {\"context\": docs, **inputs}\n",
    "\n",
    "semantic_rag = (\n",
    "    RunnableMap({\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    })\n",
    "    | RunnableLambda(get_context_dense)\n",
    "    | RunnableMap({\n",
    "        \"context\": lambda x: x[\"context\"],\n",
    "        \"question\": lambda x: x.get(\"question\", \"\"),\n",
    "    })\n",
    "    | RunnableLambda(generate_response)\n",
    ")\n",
    "\n",
    "# Now, let's test the semantic RAG pipeline with a sample query.\n",
    "response = semantic_rag.invoke({\"question\": \"کارگردان فیلم شب یلدا دانش آموخته چه رشته ای می باشد ؟\"})\n",
    "print(response[\"response\"])"
   ],
   "id": "ffd52d4b74bb2f3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehdi\\AppData\\Local\\Temp\\ipykernel_20972\\2244603330.py:9: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = llm(formatted_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مهندسی کشاورزی\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T06:52:01.151376Z",
     "start_time": "2025-06-13T06:52:01.146529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_digits_en2fa(text):\n",
    "    english_digits = '0123456789'\n",
    "    persian_digits = '۰۱۲۳۴۵۶۷۸۹'\n",
    "\n",
    "    translation_table = str.maketrans(english_digits, persian_digits)\n",
    "    return text.translate(translation_table)\n",
    "\n",
    "def parse_result(gold, generated_text) -> bool:\n",
    "    gold = convert_digits_en2fa(gold)\n",
    "    generated_text = convert_digits_en2fa(generated_text)\n",
    "\n",
    "    if gold in generated_text:\n",
    "        return True\n",
    "    if gold == \"بلی\":\n",
    "        if \"بله\" in generated_text:\n",
    "            return True\n",
    "\n",
    "    return False"
   ],
   "id": "13f678b45119bb70",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T09:40:56.340910Z",
     "start_time": "2025-06-13T09:03:19.880644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "responses = []\n",
    "correct = 0\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    if i<len(responses):\n",
    "        continue\n",
    "    try:\n",
    "        response = semantic_rag.invoke({\"question\": row[\"question\"]})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(20)\n",
    "        response = semantic_rag.invoke({\"question\": row[\"question\"]})\n",
    "    if parse_result(row[\"answer\"], response[\"response\"]):\n",
    "        correct += 1\n",
    "    print(response[\"response\"])\n",
    "    print(\"Gold\", row[\"answer\"])\n",
    "    responses.append(response)\n",
    "    print(\"-\"*25)\n",
    "    time.sleep(20)"
   ],
   "id": "937c384c1cc862dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "برای نگاناسان‌ها بله، اما درباره مردم انتس اطلاعاتی در متن موجود نیست.\n",
      "Gold بله\n",
      "-------------------------\n",
      "خیر. طبق متن، فقط نگاناسان‌ها به این زبان تکلم می‌کنند.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، متن فقط درباره مردم انتس اطلاعات دارد و به نگاناسان‌ها اشاره‌ای نمی‌کند.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "مایکل کین\n",
      "Gold مایکل کین\n",
      "-------------------------\n",
      "اطلاعات مربوط به تأسیس شرکت تکمو در متن ارائه نشده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "در متن ارائه شده به گروه نقاشان تصویرگر اشاره نشده است.\n",
      "Gold پیشارافائلی\n",
      "-------------------------\n",
      "تب\n",
      "Gold تب\n",
      "-------------------------\n",
      "خیر، نینتندو مجموعه بازی برادران سوپر اسمش را منتشر کرده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه نشده است.\n",
      "Gold سال 1953\n",
      "-------------------------\n",
      "طراحی شخصیت\n",
      "Gold انیمه و مانگا\n",
      "-------------------------\n",
      "اطلاعاتی در این زمینه در متن ارائه نشده است.\n",
      "Gold مغول‌ها\n",
      "-------------------------\n",
      "اطلاعاتی در این مورد در متن ارائه نشده است.\n",
      "Gold جیوه\n",
      "-------------------------\n",
      "خیر، در متن به آن اشاره نشده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "سونی و مایکروسافت.\n",
      "Gold مایکروسافت\n",
      "-------------------------\n",
      "اطلاعاتی در مورد شرکت تکمو در متن موجود نیست.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "جوایز گلدن گلوب به بهترین تولیدات سینمایی و تلویزیونی، هم داخلی و هم خارجی اهدا می‌گردد، اما در مورد جایزه ادبی من بوکر اطلاعاتی در متن وجود ندارد.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "متن ارائه‌شده اطلاعاتی درباره جایزه شیر طلایی ندارد.\n",
      "Gold بله\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه شده نیست.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، اطلاعاتی در این زمینه در متن ارائه نشده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، در متن ارائه شده اطلاعاتی در این مورد وجود ندارد.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، اطلاعاتی در مورد ناشر بازی ندای وظیفه در متن ارائه نشده است. اما بازی ایس کمبت ۷: آسمان‌های ناشناخته توسط بندای نامکو انترتینمنت منتشر شده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "این اطلاعات در متن موجود نیست.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "متن فقط سال تولید فیلم آلیس در شهرها (۱۹۷۴) را ذکر کرده و اطلاعاتی درباره فیلم پرومتئوس ندارد.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، توسط رابی مولر انجام شده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "بله، فیلم آلیس در شهرها درام است. در مورد فیلم نیمه ماه مارس اطلاعاتی در متن موجود نیست.\n",
      "Gold بله\n",
      "-------------------------\n",
      "فیلم آلیس در شهرها توسط ویم وندرس کارگردانی شده است، اما اطلاعاتی درباره فیلم نیمه ماه مارس در دسترس نیست.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "از سال ۱۸۵۰ میلادی.\n",
      "Gold سال 1850\n",
      "-------------------------\n",
      "بله، تاکنون ۹ نفر از خاندان آل ثانی به‌عنوان امیر قطر منصوب شده‌اند.\n",
      "Gold بله\n",
      "-------------------------\n",
      "اطلاعاتی درباره فیلم‌های حفیصه حرزی در متن ارائه نشده است.\n",
      "Gold خانه بردباری\n",
      "-------------------------\n",
      "اطلاعات مربوط به سبک فیلم‌ها در متن موجود نیست.\n",
      "Gold خانه بردباری\n",
      "-------------------------\n",
      "اطلاعات مربوط به سال انتشار فیلم‌ها در متن ارائه نشده است.\n",
      "Gold خانه بردباری\n",
      "-------------------------\n",
      "در متن به حضور حفیصه حرزی اشاره‌ای نشده است.\n",
      "Gold خانه بردباری\n",
      "-------------------------\n",
      "اطلاعاتی در این خصوص در متن موجود نیست.\n",
      "Gold 2012 سال\n",
      "-------------------------\n",
      "اطلاعاتی در مورد فروش کمپانی در متن ارائه نشده است.\n",
      "لوک اسکای‌واکر توسط جرج لوکاس پدید آمده است.\n",
      "Gold شرکت والت دیزنی\n",
      "-------------------------\n",
      "اطلاعاتی در این مورد در متن موجود نیست.\n",
      "Gold بله\n",
      "-------------------------\n",
      "فیلاریازیس.\n",
      "Gold فیلاریازیس\n",
      "-------------------------\n",
      "اطلاعاتی در این زمینه در متن ارائه نشده است.\n",
      "Gold پطر کبیر\n",
      "-------------------------\n",
      "بله، لس آنجلس تایمز که جاستین چنگ برای آن می‌نویسد، دومین روزنامه بزرگ مناطق شهری در ایالات متحده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "لس آنجلس تایمز\n",
      "Gold لس آنجلس تایمز\n",
      "-------------------------\n",
      "نویسنده نامدار آمریکایی\n",
      "Gold پدر ادبیات مدرن\n",
      "-------------------------\n",
      "بله.\n",
      "Gold بله\n",
      "-------------------------\n",
      "مجموعه تلویزیونی بریتانیایی اداره\n",
      "Gold مجموعه تلوزیونی اداره\n",
      "-------------------------\n",
      "اطلاعاتی در مورد سال راه‌اندازی شرکت‌های هواپیمایی فعال در فرودگاه در متن ارائه نشده است.\n",
      "Gold ایران ایرتور\n",
      "-------------------------\n",
      "بله، هر دو فیلم را جان وو کارگردانی کرده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "بله، هر دو در سال ۱۹۸۶ منتشر شده‌اند.\n",
      "Gold بله\n",
      "-------------------------\n",
      "بله، این دو فیلم به طور مشترک برنده جایزه اسکار بهترین فیلم مستند شده‌اند.\n",
      "Gold بله\n",
      "-------------------------\n",
      "نیما عالمیان\n",
      "Gold نیما عالمیان\n",
      "-------------------------\n",
      "خیر، نیما عالمیان فعالیت خود را از سال ۲۰۰۰ شروع کرده است. اطلاعاتی درباره نوشاد عالمیان در متن وجود ندارد.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "خیر، فقط نوشاد عالمیان عضو باشگاه توقینیه فویلارد است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "بر اساس این متن، تنها نیما عالمیان بازیکن تنیس روی میز و ملی‌پوش اهل ایران معرفی شده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "مهندسی کشاورزی\n",
      "Gold مهندسی کشاورزی\n",
      "-------------------------\n",
      "خیر، سیمرغ بلورین برای فیلم مستند «اتاق صعود» به رضا فرهمند اهدا شده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "اتاق صعود\n",
      "Gold فیلم نیمه بلند اتاق صعود\n",
      "-------------------------\n",
      "اطلاعاتی در این مورد در متن موجود نیست.\n",
      "Gold پینوکیو\n",
      "-------------------------\n",
      "اطلاعاتی در مورد پخش فیلم‌های کیم یونگ-کوانگ در چین، تایلند و ژاپن در متن ارائه نشده است.\n",
      "Gold پینوکیو\n",
      "-------------------------\n",
      "اطلاعاتی در مورد فرایند برش در متن ارائه نشده است.\n",
      "Gold برش ویفر یا ویفر دایسینگ\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه نشده است.\n",
      "Gold عروس آتش\n",
      "-------------------------\n",
      "اطلاعات موجود کارگردان فیلم‌های برنده جایزه را مشخص نمی‌کند.\n",
      "Gold عروس آتش\n",
      "-------------------------\n",
      "بله، هر دو.\n",
      "Gold بله\n",
      "-------------------------\n",
      "سال تأسیس تیم فراری در متن ذکر نشده است.\n",
      "Gold ۱۹۲۹\n",
      "-------------------------\n",
      "بله، درست است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "اطلاعاتی در مورد موجودات منقرض شده در جنگل گیر در متن ارائه نشده است.\n",
      "Gold شیر ایرانی\n",
      "-------------------------\n",
      "چارلی چاپلین.\n",
      "Gold چارلی چاپلین\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه شده نیست.\n",
      "Gold آدواله آکینویه آگباجه\n",
      "-------------------------\n",
      "اطلاعاتی در مورد ملیت بازیگر در متن موجود نیست.\n",
      "Gold بله\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه نشده است.\n",
      "Gold هاوارد کوهن و اریک دی آربلوف\n",
      "-------------------------\n",
      "این اطلاعات در متن موجود نیست.\n",
      "Gold نقد مکتب روان‌شناسی رفتارگرایی\n",
      "-------------------------\n",
      "اطلاعاتی در مورد اینکه رمان \"۱۳ دلیل برای اینکه\" ابتدا به صورت نمایشنامه درآمده باشد، در متن ارائه نشده است.\n",
      "Gold ۱۹۶۳ سال\n",
      "-------------------------\n",
      "راک\n",
      "Gold راک\n",
      "-------------------------\n",
      "جیمز براون، از پیشگامان موسیقی فانک.\n",
      "Gold موسیقی فانک\n",
      "-------------------------\n",
      "بله.\n",
      "Gold بله\n",
      "-------------------------\n",
      "بله، شرکت ماهان با ۳۷ فروند هواپیما (مسافربری و باری) در مقایسه با ۱۲ فروند هواپیمای مسافربری ایران ایرتور، تعداد بیشتری هواپیما دارد.\n",
      "Gold بله\n",
      "-------------------------\n",
      "پیروز یکم پادشاه ایرانی بود، اما محمد ظاهرشاه خیر.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "اطلاعاتی در مورد بازی ریمن ریوینگ رابیدها در متن ارائه نشده است.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "بله، فیلم بی‌خانمانی در آمریکا برنده جایزه اسکار شده است. اما اطلاعاتی درباره فیلم دیوانه از قفس پرید در متن شما وجود ندارد.\n",
      "Gold بله\n",
      "-------------------------\n",
      "اطلاعاتی در این خصوص در متن ارائه نشده است.\n",
      "Gold ده‌سالگی\n",
      "-------------------------\n",
      "خیر، قرار ندارد.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "مانجاری فاندیس\n",
      "Gold مانجاری فاندیس\n",
      "-------------------------\n",
      "خیر.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "هیچ‌کدام\n",
      "Gold مس\n",
      "-------------------------\n",
      "بله، در متن تنها به او به عنوان خالق مجموعه هری پاتر اشاره شده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "نخستین پادشاه بود.\n",
      "Gold نخستین\n",
      "-------------------------\n",
      "بله.\n",
      "Gold بله\n",
      "-------------------------\n",
      "خیر، متن به این موضوع اشاره نکرده است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "اطلاعاتی در این مورد در متن ارائه نشده است.\n",
      "Gold امیرکبیر\n",
      "-------------------------\n",
      "اطلاعاتی در مورد سن ترور ناصرالدین شاه در متن ارائه نشده است.\n",
      "Gold 65\n",
      "-------------------------\n",
      "متن ارائه شده اطلاعاتی در مورد طول پادشاهی ناصرالدین شاه ندارد.\n",
      "Gold 50 سال\n",
      "-------------------------\n",
      "ناصرالدین شاه قاجار.\n",
      "Gold صاحبقران\n",
      "-------------------------\n",
      "خیر، فقط جوزپه وردی ایتالیایی بود.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "بله، اتومبیل‌دزدی بزرگ نیز از طراحی جهان باز برخوردار است.\n",
      "Gold بله\n",
      "-------------------------\n",
      "متن ارائه شده بیان می‌کند که در سپتیسمی ممکن است دمای بدن بالا نباشد یا حتی کاهش یابد، نه افزایش.\n",
      "Gold تب\n",
      "-------------------------\n",
      "تشنج در علائم و نشانه‌های ارائه‌شده ذکر نشده است.\n",
      "Gold تب\n",
      "-------------------------\n",
      "دیوید والاس یک شخصیت تخیلی است. در مورد لوک اسکای‌واکر اطلاعاتی در دسترس نیست.\n",
      "Gold بله\n",
      "-------------------------\n",
      "دیوید والاس فردی صبور، درک‌کننده و قدردان کارمندان خوب است. در مورد لوک اسکای‌واکر اطلاعاتی در متن ارائه نشده است.\n",
      "Gold تخیلی\n",
      "-------------------------\n",
      "فقط لوک اسکای‌واکر توسط مارک همیل به تصویر کشیده شده است. درباره دیوید والاس در متن اطلاعاتی نیست.\n",
      "Gold خیر\n",
      "-------------------------\n",
      "این اطلاعات در متن ارائه نشده است.\n",
      "Gold آپاچی سابورژن\n",
      "-------------------------\n",
      "فار کرای پرایمال در سبک اکشن و ماجراجویی است. اطلاعاتی درباره سبک فار کرای در متن وجود ندارد.\n",
      "Gold اکشن و ماجراجویی\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation:",
   "id": "e94549ab19389313"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Accuracy:",
   "id": "f2cd5a048bf061c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:11:44.330084Z",
     "start_time": "2025-06-13T10:11:44.322325Z"
    }
   },
   "cell_type": "code",
   "source": "print(correct / len(test_df))",
   "id": "f78ed4cc23d6330c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4342105263157895\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Accuracy LLM as Judge:",
   "id": "7cadcc16fb3dc5df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema import HumanMessage\n",
    "import time\n",
    "\n",
    "class QuestionAnsweringJudgement(BaseModel):\n",
    "    same_result: bool = Field(description=\"Analyzes if results are same set true\")\n",
    "    reason: str = Field(description=\"Reason if results are same or not same\")\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(QuestionAnsweringJudgement)"
   ],
   "id": "c27706deebc5119"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "llm_as_judge_responses = []\n",
    "llm_as_judge_correct = 0\n",
    "for i, row in test_df.iterrows():\n",
    "    prompt = f\"\"\"Judge question for generated answer with true answer and output result in json format in true false format with reason\n",
    "    question: {row['question']}\n",
    "    true answer: {row['answer']}\n",
    "    generated answer: {responses[i]['response']}\n",
    "    context for true answer: {row['context']}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm_with_structure.invoke([HumanMessage(content=prompt)])\n",
    "        llm_as_judge_responses.append(response)\n",
    "        if response.same_result:\n",
    "            llm_as_judge_correct += 1\n",
    "    except Exception as e:\n",
    "       print(e)\n",
    "       time.sleep(10)"
   ],
   "id": "6cf1587f884e239d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(llm_as_judge_correct / len(test_df))",
   "id": "f79f9902d92619f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### F1",
   "id": "a150363b864f28f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:42.072575Z",
     "start_time": "2025-06-13T10:42:42.060842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import string\n",
    "\n",
    "def compute_f1_metrics(generated_response: str, ground_truth_answer: str):\n",
    "    \"\"\"\n",
    "    Calculates F1, precision, and recall for text quality evaluation.\n",
    "\n",
    "    This function compares the words in the generated response to the\n",
    "    words in the ground-truth answer, based on the methodology used in\n",
    "    the HotpotQA evaluation script.\n",
    "\n",
    "    Args:\n",
    "        generated_response: The text generated by the model.\n",
    "        ground_truth_answer: The correct, reference text.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the F1 score, precision, and recall.\n",
    "    \"\"\"\n",
    "    # Normalize and split the text into a list of words (tokens)\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation+\"،\")\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    prediction_tokens = remove_punc(generated_response).lower().split()\n",
    "    ground_truth_tokens = remove_punc(ground_truth_answer).lower().split()\n",
    "\n",
    "    # If either the prediction or the ground truth is empty, metrics are 0\n",
    "    if not prediction_tokens or not ground_truth_tokens:\n",
    "        return {'f1': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    # Use collections.Counter to count word frequencies\n",
    "    prediction_counter = collections.Counter(prediction_tokens)\n",
    "    ground_truth_counter = collections.Counter(ground_truth_tokens)\n",
    "\n",
    "    # Find the common words, respecting their frequency\n",
    "    common_words_counter = prediction_counter & ground_truth_counter\n",
    "    num_common_words = sum(common_words_counter.values())\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = num_common_words / len(prediction_tokens)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = num_common_words / len(ground_truth_tokens)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    if (precision + recall) > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0.0\n",
    "\n",
    "    return {'f1': f1, 'precision': precision, 'recall': recall}"
   ],
   "id": "4ace689f2a15ffb1",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:44.686494Z",
     "start_time": "2025-06-13T10:42:44.664766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precisions, recalls, f1s = [], [], []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    scores = compute_f1_metrics(responses[i][\"response\"], row[\"answer\"])\n",
    "    precisions.append(scores[\"precision\"])\n",
    "    recalls.append(scores[\"recall\"])\n",
    "    f1s.append(scores[\"f1\"])\n"
   ],
   "id": "19343f080484b3de",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:46.439742Z",
     "start_time": "2025-06-13T10:42:46.433519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "print(\"Average precision:\", np.mean(precisions))\n",
    "print(\"Average recall:\", np.mean(recalls))\n",
    "print(\"Average F1:\", np.mean(f1s))"
   ],
   "id": "d30e84f1f7855390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision: 0.20543545698873594\n",
      "Average recall: 0.4469298245614035\n",
      "Average F1: 0.2324362339338101\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HotpotQA Evaluation scripts:",
   "id": "3e593da01a390586"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:56.520064Z",
     "start_time": "2025-06-13T10:42:56.498075Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 43,
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def normalize_answer(s):\n",
    "\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation+\"،\")\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    normalized_prediction = normalize_answer(prediction)\n",
    "    normalized_ground_truth = normalize_answer(ground_truth)\n",
    "\n",
    "    ZERO_METRIC = (0, 0, 0)\n",
    "\n",
    "    if normalized_prediction in ['بله', 'خیر', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "    if normalized_ground_truth in ['بله', 'خیر', 'noanswer'] and normalized_prediction != normalized_ground_truth:\n",
    "        return ZERO_METRIC\n",
    "\n",
    "    prediction_tokens = normalized_prediction.split()\n",
    "    ground_truth_tokens = normalized_ground_truth.split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return ZERO_METRIC\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def update_answer(metrics, prediction, gold):\n",
    "    em = exact_match_score(prediction, gold)\n",
    "    f1, prec, recall = f1_score(prediction, gold)\n",
    "    metrics['em'] += float(em)\n",
    "    metrics['f1'] += f1\n",
    "    metrics['prec'] += prec\n",
    "    metrics['recall'] += recall\n",
    "    return em, prec, recall\n",
    "\n",
    "def update_sp(metrics, prediction, gold):\n",
    "    cur_sp_pred = set(map(tuple, prediction))\n",
    "    gold_sp_pred = set(map(tuple, gold))\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for e in cur_sp_pred:\n",
    "        if e in gold_sp_pred:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    for e in gold_sp_pred:\n",
    "        if e not in cur_sp_pred:\n",
    "            fn += 1\n",
    "    prec = 1.0 * tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    recall = 1.0 * tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    f1 = 2 * prec * recall / (prec + recall) if prec + recall > 0 else 0.0\n",
    "    em = 1.0 if fp + fn == 0 else 0.0\n",
    "    metrics['sp_em'] += em\n",
    "    metrics['sp_f1'] += f1\n",
    "    metrics['sp_prec'] += prec\n",
    "    metrics['sp_recall'] += recall\n",
    "    return em, prec, recall\n",
    "\n",
    "def eval(prediction, gold_file):\n",
    "    with open(gold_file, 'r', encoding=\"utf-8\") as f:\n",
    "        gold = json.load(f)\n",
    "\n",
    "    metrics = {'em': 0, 'f1': 0, 'prec': 0, 'recall': 0,\n",
    "        'sp_em': 0, 'sp_f1': 0, 'sp_prec': 0, 'sp_recall': 0,\n",
    "        'joint_em': 0, 'joint_f1': 0, 'joint_prec': 0, 'joint_recall': 0}\n",
    "    count = 0\n",
    "    for dp in gold:\n",
    "        cur_id = dp['id']\n",
    "\n",
    "        supporting_facts = []\n",
    "        for t in dp['supporting_facts']:\n",
    "            for item in t[1]:\n",
    "                supporting_facts.append([t[0], int(item)])\n",
    "        dp['supporting_facts'] = supporting_facts\n",
    "\n",
    "        can_eval_joint = True\n",
    "        if cur_id not in prediction['answer']:\n",
    "            # print('missing answer {}'.format(cur_id))\n",
    "            can_eval_joint = False\n",
    "            continue\n",
    "        else:\n",
    "            em, prec, recall = update_answer(\n",
    "                metrics, prediction['answer'][cur_id], dp['answer'])\n",
    "        if cur_id not in prediction['sp']:\n",
    "            print('missing sp fact {}'.format(cur_id))\n",
    "            can_eval_joint = False\n",
    "        else:\n",
    "            sp_em, sp_prec, sp_recall = update_sp(\n",
    "                metrics, prediction['sp'][cur_id], dp['supporting_facts'])\n",
    "        count += 1\n",
    "\n",
    "        if can_eval_joint:\n",
    "            joint_prec = prec * sp_prec\n",
    "            joint_recall = recall * sp_recall\n",
    "            if joint_prec + joint_recall > 0:\n",
    "                joint_f1 = 2 * joint_prec * joint_recall / (joint_prec + joint_recall)\n",
    "            else:\n",
    "                joint_f1 = 0.\n",
    "            joint_em = em * sp_em\n",
    "\n",
    "            metrics['joint_em'] += joint_em\n",
    "            metrics['joint_f1'] += joint_f1\n",
    "            metrics['joint_prec'] += joint_prec\n",
    "            metrics['joint_recall'] += joint_recall\n",
    "\n",
    "    # N = len(gold)\n",
    "    for k in metrics.keys():\n",
    "        # metrics[k] /= N\n",
    "        metrics[k] = metrics[k] / count if count > 0 else 0.0\n",
    "\n",
    "    print(metrics)"
   ],
   "id": "25b441b482f731fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:53.854089Z",
     "start_time": "2025-06-13T10:42:53.815890Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of supporting facts: 3.0\n"
     ]
    }
   ],
   "execution_count": 42,
   "source": [
    "# prepare prediction format for eval\n",
    "prediction = {'answer':{},'sp':{}}\n",
    "sps_count = 0\n",
    "for idx, res in enumerate(responses):\n",
    "    sps = []\n",
    "    for context in res[\"context\"]:\n",
    "        sps.append([context.metadata[\"title\"], context.metadata[\"index\"]])\n",
    "    answer = res[\"response\"]\n",
    "    sample_id = int(test_df.iloc[idx][\"id\"])\n",
    "\n",
    "    prediction['answer'][sample_id] = answer\n",
    "    prediction['sp'][sample_id] = sps\n",
    "    sps_count += len(sps)\n",
    "\n",
    "print(f'Average number of supporting facts: {sps_count/len(responses)}')"
   ],
   "id": "eb96c5df2cd06760"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:42:57.696913Z",
     "start_time": "2025-06-13T10:42:57.672187Z"
    }
   },
   "cell_type": "code",
   "source": "eval(prediction, \"test_data.json\")",
   "id": "9218e643d9e0101",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'em': 0.13157894736842105, 'f1': 0.18629385964912282, 'prec': 0.17866019214703424, 'recall': 0.2166666666666667, 'sp_em': 0.02631578947368421, 'sp_f1': 0.5220238095238092, 'sp_prec': 0.7214912280701758, 'sp_recall': 0.4521929824561404, 'joint_em': 0.013157894736842105, 'joint_f1': 0.12197037726816125, 'joint_prec': 0.150717940685046, 'joint_recall': 0.12682748538011693}\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PQUAD",
   "id": "5b7bb23df51135d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96dd85107ed12c9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
