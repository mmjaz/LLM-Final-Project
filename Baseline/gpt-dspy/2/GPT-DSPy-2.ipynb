{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9e22f8",
   "metadata": {},
   "source": [
    "# MHQA with Advanced DSPy Optimization\n",
    "\n",
    "We use different DSPy-based prompt optimization for PersianMHQA and PQUAD datasets using advanced optimization techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ac2997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 152 test examples\n",
      "Loaded 400 train examples\n",
      "Loaded 150 PQUAD examples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "with open(\"../../../data/test_data.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "with open(\"../../../data/train_data.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "pquad_df = pd.read_csv('../../../data/pquad/pquad_questions.csv', encoding='utf-8')\n",
    "pquad_data = pquad_df.to_dict(orient='records')[:150]  # Use first 150 samples\n",
    "\n",
    "print(f\"Loaded {len(test_data)} test examples\")\n",
    "print(f\"Loaded {len(train_data)} train examples\") \n",
    "print(f\"Loaded {len(pquad_data)} PQUAD examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907f950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "# Primary LM for generation\n",
    "lm = dspy.LM(\n",
    "    model=f\"openai/{MODEL_NAME}\",\n",
    "    api_key=os.getenv(\"METIS_API_KEY\"),\n",
    "    api_base=\"https://api.metisai.ir/openai/v1\",\n",
    "    max_tokens=300,  \n",
    "    temperature=0.1   \n",
    ")\n",
    "\n",
    "# Secondary LM for evaluation \n",
    "lm_reasoning = dspy.LM(\n",
    "    model=f\"openai/{MODEL_NAME}\",\n",
    "    api_key=os.getenv(\"METIS_API_KEY\"),\n",
    "    api_base=\"https://api.metisai.ir/openai/v1\",\n",
    "    max_tokens=500,  # More tokens for reasoning\n",
    "    temperature=0.0   # Deterministic for evaluation\n",
    ")\n",
    "\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa534e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced DSPy signatures with more detailed instructions\n",
    "class EnhancedPersianQASignature(dspy.Signature):\n",
    "    \"\"\"Answer Persian/Farsi questions with high accuracy. Focus on providing precise, concise answers that directly address the question. Consider Persian language nuances and cultural context.\"\"\"\n",
    "    question = dspy.InputField(desc=\"Persian question requiring a factual answer\")\n",
    "    answer = dspy.OutputField(desc=\"Precise, concise Persian answer (one to three words when possible)\")\n",
    "\n",
    "class EnhancedPersianQAWithReasoningSignature(dspy.Signature):\n",
    "    \"\"\"Answer Persian/Farsi questions using step-by-step reasoning. Break down multi-hop questions into logical steps.\"\"\"\n",
    "    question = dspy.InputField(desc=\"Persian question requiring multi-step reasoning\")\n",
    "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning process in Persian\")\n",
    "    answer = dspy.OutputField(desc=\"Final precise Persian answer based on reasoning\")\n",
    "\n",
    "class PersianQAWithContextSignature(dspy.Signature):\n",
    "    \"\"\"Answer Persian questions by first analyzing the question type and required information.\"\"\"\n",
    "    question = dspy.InputField(desc=\"Persian question to analyze and answer\")\n",
    "    question_type = dspy.OutputField(desc=\"Type of question (factual, comparison, temporal, etc.)\")\n",
    "    key_entities = dspy.OutputField(desc=\"Key entities or concepts mentioned in the question\")\n",
    "    answer = dspy.OutputField(desc=\"Accurate Persian answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSPy modules with multi-stage processing\n",
    "class EnhancedPersianQAModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(EnhancedPersianQASignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        result = self.generate_answer(question=question)\n",
    "        return dspy.Prediction(answer=result.answer)\n",
    "\n",
    "class EnhancedPersianQAWithReasoningModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(EnhancedPersianQAWithReasoningSignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        result = self.generate_answer(question=question)\n",
    "        return dspy.Prediction(answer=result.answer, reasoning=getattr(result, 'reasoning', ''))\n",
    "\n",
    "class MultiStagePersianQAModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.analyze_question = dspy.Predict(PersianQAWithContextSignature)\n",
    "        self.refine_answer = dspy.Predict(EnhancedPersianQASignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        # first analyze question\n",
    "        analysis = self.analyze_question(question=question)\n",
    "        \n",
    "        # then generate refined answer\n",
    "        refined = self.refine_answer(question=question)\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            answer=refined.answer,\n",
    "            question_type=getattr(analysis, 'question_type', ''),\n",
    "            key_entities=getattr(analysis, 'key_entities', '')\n",
    "        )\n",
    "\n",
    "class EnsemblePersianQAModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qa_direct = dspy.Predict(EnhancedPersianQASignature)\n",
    "        self.qa_reasoning = dspy.ChainOfThought(EnhancedPersianQAWithReasoningSignature)\n",
    "        self.qa_context = dspy.Predict(PersianQAWithContextSignature)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        # Get predictions from all approaches\n",
    "        direct = self.qa_direct(question=question)\n",
    "        reasoning = self.qa_reasoning(question=question)\n",
    "        context = self.qa_context(question=question)\n",
    "        \n",
    "        # Simple voting/selection mechanism \n",
    "        answers = [direct.answer, reasoning.answer, context.answer]\n",
    "        \n",
    "        final_answer = reasoning.answer if hasattr(reasoning, 'answer') else direct.answer\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            answer=final_answer,\n",
    "            direct_answer=direct.answer,\n",
    "            reasoning_answer=reasoning.answer,\n",
    "            context_answer=context.answer\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_model_answer(model_answer: str) -> str:\n",
    "    if not model_answer:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove various tags and formatting\n",
    "    cleaned = re.sub(r'<ANSWER>(.*?)</ANSWER>', r'\\1', model_answer, flags=re.DOTALL|re.IGNORECASE)\n",
    "    cleaned = re.sub(r'<[^>]+>', '', cleaned)  # Remove any remaining tags\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)     # Normalize whitespace\n",
    "    cleaned = cleaned.strip()\n",
    "    \n",
    "    prefixes = ['پاسخ:', 'جواب:', 'Answer:', 'Response:']\n",
    "    for prefix in prefixes:\n",
    "        if cleaned.startswith(prefix):\n",
    "            cleaned = cleaned[len(prefix):].strip()\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def evaluate_answer_with_judge(question: str, correct_answer: str, model_answer: str, judge_lm) -> bool:\n",
    "    clean_answer = clean_model_answer(model_answer)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        شما یک قاضی خبره هستید که پاسخ‌های فارسی را ارزیابی می‌کنید. \n",
    "        تعیین کنید که آیا پاسخ مدل از نظر معنایی معادل پاسخ صحیح است یا خیر.\n",
    "        در نظر بگیرید که تغییرات جزئی در املا و عبارات معادل قابل قبول هستند.\n",
    "\n",
    "        سوال: {question}\n",
    "\n",
    "        پاسخ صحیح: {correct_answer}\n",
    "        پاسخ مدل: {clean_answer}\n",
    "\n",
    "        اگر پاسخ مدل از نظر معنایی معادل پاسخ صحیح است، فقط \"TRUE\" بنویسید.\n",
    "        در غیر این صورت فقط \"FALSE\" بنویسید.\n",
    "\n",
    "        پاسخ:\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = judge_lm(prompt)\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            response_text = str(response[0])\n",
    "        else:\n",
    "            response_text = str(response)\n",
    "        \n",
    "        return \"TRUE\" in response_text.upper()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in judge evaluation: {e}\")\n",
    "        return False\n",
    "\n",
    "evaluation_cache = {}\n",
    "\n",
    "def enhanced_accuracy_metric(gold, pred, trace=None): \n",
    "    cache_key = (gold.question, gold.answer, pred.answer)\n",
    "    \n",
    "    if cache_key in evaluation_cache:\n",
    "        return evaluation_cache[cache_key]\n",
    "    \n",
    "    judge_lm = lm_reasoning\n",
    "    result = evaluate_answer_with_judge(gold.question, gold.answer, pred.answer, judge_lm)\n",
    "    \n",
    "    evaluation_cache[cache_key] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b65c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHQA Train examples: 80\n",
      "MHQA Test examples: 152\n",
      "\n",
      "Training data distribution:\n",
      "  اسامی عام: 8\n",
      "  شخص: 9\n",
      "  بلی/خیر: 13\n",
      "  تاریخ: 7\n",
      "  رویداد: 4\n",
      "  مکان: 6\n",
      "  اسامی خاص دیگر: 6\n",
      "  شماره: 6\n",
      "  کار هنری: 7\n",
      "  گروه یا سازمان: 7\n",
      "  صفت: 6\n",
      "  : 1\n"
     ]
    }
   ],
   "source": [
    "# Enhanced data preparation with stratified sampling\n",
    "def prepare_enhanced_dspy_examples(data_list, sample_size=None):\n",
    "    examples = []\n",
    "    \n",
    "    for item in data_list:\n",
    "        example = dspy.Example(\n",
    "            question=item['question'],\n",
    "            answer=item['answer'],\n",
    "            question_type=item.get('type', 'unknown'),\n",
    "            answer_type=item.get('answer_type', 'unknown')\n",
    "        ).with_inputs('question')\n",
    "        examples.append(example)\n",
    "    \n",
    "    # Stratified sampling if needed\n",
    "    if sample_size and sample_size < len(examples):\n",
    "        # Group by answer type for balanced sampling\n",
    "        type_groups = defaultdict(list)\n",
    "        for ex in examples:\n",
    "            type_groups[ex.answer_type].append(ex)\n",
    "        \n",
    "        sampled = []\n",
    "        samples_per_type = max(1, sample_size // len(type_groups))\n",
    "        \n",
    "        for type_name, type_examples in type_groups.items():\n",
    "            n_samples = min(samples_per_type, len(type_examples))\n",
    "            sampled.extend(random.sample(type_examples, n_samples))\n",
    "        \n",
    "        # Fill remaining slots randomly\n",
    "        remaining = sample_size - len(sampled)\n",
    "        if remaining > 0:\n",
    "            remaining_examples = [ex for ex in examples if ex not in sampled]\n",
    "            if remaining_examples:\n",
    "                sampled.extend(random.sample(remaining_examples, min(remaining, len(remaining_examples))))\n",
    "        \n",
    "        return sampled[:sample_size]\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prepare enhanced datasets\n",
    "mhqa_train_examples = prepare_enhanced_dspy_examples(train_data, sample_size=80)  # Increased training size\n",
    "mhqa_test_examples = prepare_enhanced_dspy_examples(test_data)\n",
    "\n",
    "print(f\"MHQA Train examples: {len(mhqa_train_examples)}\")\n",
    "print(f\"MHQA Test examples: {len(mhqa_test_examples)}\")\n",
    "\n",
    "# Show distribution\n",
    "train_types = defaultdict(int)\n",
    "for ex in mhqa_train_examples:\n",
    "    train_types[ex.answer_type] += 1\n",
    "\n",
    "print(f\"\\nTraining data distribution:\")\n",
    "for type_name, count in train_types.items():\n",
    "    print(f\"  {type_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee8b4c",
   "metadata": {},
   "source": [
    "# MHQA Advanced Optimization Experiments\n",
    "\n",
    "We'll use multiple optimization strategies and compare their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09986598",
   "metadata": {},
   "source": [
    "## Strategy 1: Enhanced BootstrapFewShot with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41956f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 1: Enhanced BootstrapFewShot Optimization...\n",
      "Going to sample between 1 and 8 traces per predictor.\n",
      "Will attempt to bootstrap 16 candidate sets.\n",
      "Optimizing with enhanced BootstrapFewShot...\n",
      "Average Metric: 5.00 / 20 (25.0%): 100%|██████████| 20/20 [00:15<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:48:50 INFO dspy.evaluate.evaluate: Average Metric: 5 / 20 (25.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 25.0 for seed -3\n",
      "Scores so far: [25.0]\n",
      "Best score so far: 25.0\n",
      "Average Metric: 6.00 / 20 (30.0%): 100%|██████████| 20/20 [00:10<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:49:00 INFO dspy.evaluate.evaluate: Average Metric: 6 / 20 (30.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 30.0 for seed -2\n",
      "Scores so far: [25.0, 30.0]\n",
      "Best score so far: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 27/80 [01:37<03:12,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 27 examples for up to 3 rounds, amounting to 66 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:09<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:50:48 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 40.0 for seed -1\n",
      "Scores so far: [25.0, 30.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [00:46<04:53,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 7 full traces after 11 examples for up to 3 rounds, amounting to 20 attempts.\n",
      "Average Metric: 7.00 / 20 (35.0%): 100%|██████████| 20/20 [00:09<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:51:44 INFO dspy.evaluate.evaluate: Average Metric: 7 / 20 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:23<04:55,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 6 examples for up to 3 rounds, amounting to 13 attempts.\n",
      "Average Metric: 7.00 / 20 (35.0%): 100%|██████████| 20/20 [00:08<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:52:16 INFO dspy.evaluate.evaluate: Average Metric: 7 / 20 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:07<04:40,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 3 rounds, amounting to 4 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:08<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:52:31 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:17<03:31,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 3 rounds, amounting to 10 attempts.\n",
      "Average Metric: 7.00 / 20 (35.0%): 100%|██████████| 20/20 [00:08<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:52:57 INFO dspy.evaluate.evaluate: Average Metric: 7 / 20 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [00:49<05:11,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 11 examples for up to 3 rounds, amounting to 25 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:14<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:54:01 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [01:04<07:32,  6.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 10 examples for up to 3 rounds, amounting to 20 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:06<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:55:12 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4/80 [00:15<04:51,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples for up to 3 rounds, amounting to 8 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:09<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:55:38 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [00:46<04:22,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 12 examples for up to 3 rounds, amounting to 24 attempts.\n",
      "Average Metric: 7.00 / 20 (35.0%): 100%|██████████| 20/20 [00:11<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:56:35 INFO dspy.evaluate.evaluate: Average Metric: 7 / 20 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [01:12<06:15,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 13 examples for up to 3 rounds, amounting to 31 attempts.\n",
      "Average Metric: 7.00 / 20 (35.0%): 100%|██████████| 20/20 [00:07<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:57:55 INFO dspy.evaluate.evaluate: Average Metric: 7 / 20 (35.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [01:10<04:20,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 17 examples for up to 3 rounds, amounting to 35 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:15<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:59:21 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:11<07:31,  5.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 3 rounds, amounting to 4 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:08<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 11:59:41 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 20/80 [01:20<04:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 20 examples for up to 3 rounds, amounting to 44 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:07<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:01:09 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 23/80 [01:32<03:48,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 23 examples for up to 3 rounds, amounting to 53 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:07<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:02:49 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [00:35<05:17,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 8 examples for up to 3 rounds, amounting to 14 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:09<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:03:34 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0, 40.0, 40.0, 40.0]\n",
      "Best score so far: 40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:22<04:41,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 3 rounds, amounting to 14 attempts.\n",
      "Average Metric: 9.00 / 20 (45.0%): 100%|██████████| 20/20 [00:08<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:04:06 INFO dspy.evaluate.evaluate: Average Metric: 9 / 20 (45.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 45.0 for seed 14\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0, 40.0, 40.0, 40.0, 45.0]\n",
      "Best score so far: 45.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [00:54<06:19,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples for up to 3 rounds, amounting to 22 attempts.\n",
      "Average Metric: 8.00 / 20 (40.0%): 100%|██████████| 20/20 [00:08<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:05:08 INFO dspy.evaluate.evaluate: Average Metric: 8 / 20 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [25.0, 30.0, 40.0, 35.0, 35.0, 40.0, 35.0, 40.0, 40.0, 40.0, 35.0, 35.0, 40.0, 40.0, 40.0, 40.0, 40.0, 45.0, 40.0]\n",
      "Best score so far: 45.0\n",
      "19 candidate programs found.\n",
      "Strategy 1 optimization completed!\n",
      "\n",
      "============================================================\n",
      "STRATEGY 1 - ENHANCED BOOTSTRAPFEWSHOT RESULTS:\n",
      "============================================================\n",
      "\n",
      "Predictor 1:\n",
      "Signature: EnhancedPersianQASignature(question -> answer\n",
      "    instructions='Answer Persian/Farsi questions with high accuracy. Focus on providing precise, concise answers that directly address the question. Consider Persian language nuances and cultural context.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring a factual answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Precise, concise Persian answer (one to three words when possible)', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 6\n",
      "  Demo 1: کدام یک از سبک‌هایی که فرانک وینسنت زاپا در آن آهنگسازی کرده تحت تأثیر ژانرهایی ... -> راک\n",
      "  Demo 2: از بین کشورهای پرتغال و اسرائیل در کدام یک زودتر مسابقه آواز یوروویژن برگزار شد ... -> پرتغال\n",
      "  Demo 3: شرکتی که ب‌ام‌و ایکس۷ و ب‌ام‌و سری ۷ توسط آن ساخته شده است چه نام دارد ؟... -> ب‌ام‌و\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Strategy 1: Enhanced BootstrapFewShot\n",
    "print(\"Strategy 1: Enhanced BootstrapFewShot Optimization...\")\n",
    "\n",
    "# Create enhanced model\n",
    "mhqa_enhanced_model = EnhancedPersianQAModule()\n",
    "\n",
    "# Enhanced teleprompter with more aggressive search\n",
    "teleprompter_enhanced = dspy.BootstrapFewShotWithRandomSearch(\n",
    "    metric=enhanced_accuracy_metric,\n",
    "    max_bootstrapped_demos=8,    # Increased\n",
    "    max_labeled_demos=6,         # Increased  \n",
    "    max_rounds=3,                # More rounds\n",
    "    num_candidate_programs=16,   # More candidates\n",
    "    num_threads=4                # Parallel processing\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "print(\"Optimizing with enhanced BootstrapFewShot...\")\n",
    "mhqa_enhanced_optimized = teleprompter_enhanced.compile(\n",
    "    mhqa_enhanced_model,\n",
    "    trainset=mhqa_train_examples,\n",
    "    valset=mhqa_train_examples[:20]  # Use subset for validation\n",
    ")\n",
    "\n",
    "print(\"Strategy 1 optimization completed!\")\n",
    "\n",
    "# Show optimized prompt\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 1 - ENHANCED BOOTSTRAPFEWSHOT RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for i, predictor in enumerate(mhqa_enhanced_optimized.predictors()):\n",
    "    print(f\"\\nPredictor {i+1}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(f\"Demonstrations: {len(predictor.demos)}\")\n",
    "        for j, demo in enumerate(predictor.demos[:3]):\n",
    "            print(f\"  Demo {j+1}: {demo.question[:80]}... -> {demo.answer}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446adaa1",
   "metadata": {},
   "source": [
    "## Strategy 2: Multi-Stage Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616e0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 2: Multi-Stage Processing Optimization...\n",
      "Optimizing multi-stage model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [02:25<09:00,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 17 examples for up to 3 rounds, amounting to 40 attempts.\n",
      "Strategy 2 optimization completed!\n",
      "\n",
      "============================================================\n",
      "STRATEGY 2 - MULTI-STAGE PROCESSING RESULTS:\n",
      "============================================================\n",
      "\n",
      "Predictor 1:\n",
      "Signature: PersianQAWithContextSignature(question -> question_type, key_entities, answer\n",
      "    instructions='Answer Persian questions by first analyzing the question type and required information.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question to analyze and answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    question_type = Field(annotation=str required=True json_schema_extra={'desc': 'Type of question (factual, comparison, temporal, etc.)', '__dspy_field_type': 'output', 'prefix': 'Question Type:'})\n",
      "    key_entities = Field(annotation=str required=True json_schema_extra={'desc': 'Key entities or concepts mentioned in the question', '__dspy_field_type': 'output', 'prefix': 'Key Entities:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Accurate Persian answer', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 6\n",
      "\n",
      "Predictor 2:\n",
      "Signature: EnhancedPersianQASignature(question -> answer\n",
      "    instructions='Answer Persian/Farsi questions with high accuracy. Focus on providing precise, concise answers that directly address the question. Consider Persian language nuances and cultural context.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring a factual answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Precise, concise Persian answer (one to three words when possible)', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 6\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Strategy 2: Multi-Stage Processing\n",
    "print(\"Strategy 2: Multi-Stage Processing Optimization...\")\n",
    "\n",
    "# Create multi-stage model\n",
    "mhqa_multistage_model = MultiStagePersianQAModule()\n",
    "\n",
    "# Optimize multi-stage model\n",
    "teleprompter_multistage = dspy.BootstrapFewShot(\n",
    "    metric=enhanced_accuracy_metric,\n",
    "    max_bootstrapped_demos=6,\n",
    "    max_labeled_demos=4,\n",
    "    max_rounds=3\n",
    ")\n",
    "\n",
    "print(\"Optimizing multi-stage model...\")\n",
    "mhqa_multistage_optimized = teleprompter_multistage.compile(\n",
    "    mhqa_multistage_model,\n",
    "    trainset=mhqa_train_examples\n",
    ")\n",
    "\n",
    "print(\"Strategy 2 optimization completed!\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 2 - MULTI-STAGE PROCESSING RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for i, predictor in enumerate(mhqa_multistage_optimized.predictors()):\n",
    "    print(f\"\\nPredictor {i+1}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(f\"Demonstrations: {len(predictor.demos)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db94a44",
   "metadata": {},
   "source": [
    "## Strategy 3: Ensemble Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7280d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 3: Ensemble Approach Optimization...\n",
      "Optimizing ensemble model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 12/80 [02:23<13:32, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 12 examples for up to 2 rounds, amounting to 19 attempts.\n",
      "Strategy 3 optimization completed!\n",
      "\n",
      "============================================================\n",
      "STRATEGY 3 - ENSEMBLE APPROACH RESULTS:\n",
      "============================================================\n",
      "\n",
      "Predictor 1:\n",
      "Signature: EnhancedPersianQASignature(question -> answer\n",
      "    instructions='Answer Persian/Farsi questions with high accuracy. Focus on providing precise, concise answers that directly address the question. Consider Persian language nuances and cultural context.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring a factual answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Precise, concise Persian answer (one to three words when possible)', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "Predictor 2:\n",
      "Signature: StringSignature(question -> reasoning, answer\n",
      "    instructions='Answer Persian/Farsi questions using step-by-step reasoning. Break down multi-hop questions into logical steps.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring multi-step reasoning', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'desc': 'Step-by-step reasoning process in Persian', '__dspy_field_type': 'output', 'prefix': 'Reasoning:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Final precise Persian answer based on reasoning', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "\n",
      "Predictor 3:\n",
      "Signature: PersianQAWithContextSignature(question -> question_type, key_entities, answer\n",
      "    instructions='Answer Persian questions by first analyzing the question type and required information.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question to analyze and answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    question_type = Field(annotation=str required=True json_schema_extra={'desc': 'Type of question (factual, comparison, temporal, etc.)', '__dspy_field_type': 'output', 'prefix': 'Question Type:'})\n",
      "    key_entities = Field(annotation=str required=True json_schema_extra={'desc': 'Key entities or concepts mentioned in the question', '__dspy_field_type': 'output', 'prefix': 'Key Entities:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Accurate Persian answer', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Strategy 3: Ensemble Approach\n",
    "print(\"Strategy 3: Ensemble Approach Optimization...\")\n",
    "\n",
    "# Create ensemble model\n",
    "mhqa_ensemble_model = EnsemblePersianQAModule()\n",
    "\n",
    "# Optimize ensemble\n",
    "teleprompter_ensemble = dspy.BootstrapFewShot(\n",
    "    metric=enhanced_accuracy_metric,\n",
    "    max_bootstrapped_demos=5,\n",
    "    max_labeled_demos=3,\n",
    "    max_rounds=2\n",
    ")\n",
    "\n",
    "print(\"Optimizing ensemble model...\")\n",
    "mhqa_ensemble_optimized = teleprompter_ensemble.compile(\n",
    "    mhqa_ensemble_model,\n",
    "    trainset=mhqa_train_examples\n",
    ")\n",
    "\n",
    "print(\"Strategy 3 optimization completed!\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 3 - ENSEMBLE APPROACH RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for i, predictor in enumerate(mhqa_ensemble_optimized.predictors()):\n",
    "    print(f\"\\nPredictor {i+1}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77d265",
   "metadata": {},
   "source": [
    "## Strategy 4: Enhanced Reasoning with CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "499cbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy 4: Enhanced CoT Reasoning Optimization...\n",
      "Going to sample between 1 and 10 traces per predictor.\n",
      "Will attempt to bootstrap 20 candidate sets.\n",
      "Optimizing enhanced reasoning model...\n",
      "Average Metric: 7.00 / 14 (50.0%):  52%|█████▏    | 13/25 [00:22<00:16,  1.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:10:19 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 25 (48.0%): 100%|██████████| 25/25 [00:32<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:10:29 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 48.0 for seed -3\n",
      "Scores so far: [48.0]\n",
      "Best score so far: 48.0\n",
      "Average Metric: 13.00 / 25 (52.0%): 100%|██████████| 25/25 [00:24<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:10:54 INFO dspy.evaluate.evaluate: Average Metric: 13 / 25 (52.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 52.0 for seed -2\n",
      "Scores so far: [48.0, 52.0]\n",
      "Best score so far: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 17/80 [01:39<06:10,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 17 examples for up to 4 rounds, amounting to 38 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:26<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:13:00 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0]\n",
      "Best score so far: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 11/80 [01:46<11:08,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 7 full traces after 11 examples for up to 4 rounds, amounting to 24 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:26<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:15:13 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0]\n",
      "Best score so far: 52.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 5/80 [01:01<15:25, 12.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 4 rounds, amounting to 14 attempts.\n",
      "Average Metric: 14.00 / 25 (56.0%): 100%|██████████| 25/25 [00:27<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:16:43 INFO dspy.evaluate.evaluate: Average Metric: 14 / 25 (56.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 56.0 for seed 1\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 2/80 [00:21<13:48, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 4 rounds, amounting to 5 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:23<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:17:28 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:43<08:58,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 4 rounds, amounting to 12 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:26<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:18:38 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:59<12:07,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples for up to 4 rounds, amounting to 13 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:24<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:20:02 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 25/80 [04:57<10:55, 11.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 25 examples for up to 4 rounds, amounting to 75 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:25:21 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [01:47<09:14,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 13 examples for up to 4 rounds, amounting to 27 attempts.\n",
      "Average Metric: 12.00 / 25 (48.0%): 100%|██████████| 25/25 [00:20<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:27:29 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 18/80 [04:01<13:51, 13.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 18 examples for up to 4 rounds, amounting to 56 attempts.\n",
      "Average Metric: 13.00 / 25 (52.0%): 100%|██████████| 25/25 [00:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:31:57 INFO dspy.evaluate.evaluate: Average Metric: 13 / 25 (52.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]2025/09/06 12:32:09 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      " 16%|█▋        | 13/80 [02:48<14:28, 12.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 13 examples for up to 4 rounds, amounting to 43 attempts.\n",
      "Average Metric: 9.00 / 25 (36.0%): 100%|██████████| 25/25 [00:23<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:35:09 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/80 [02:14<10:33,  9.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 14 examples for up to 4 rounds, amounting to 35 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:30<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:37:54 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 24/80 [04:29<10:28, 11.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 10 full traces after 24 examples for up to 4 rounds, amounting to 67 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:20<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:42:44 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 15/80 [02:34<11:09, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 15 examples for up to 4 rounds, amounting to 40 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:22<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:45:41 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 22/80 [04:15<11:13, 11.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 8 full traces after 22 examples for up to 4 rounds, amounting to 68 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:25<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:50:22 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 8/80 [01:29<13:22, 11.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 8 examples for up to 4 rounds, amounting to 17 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:23<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:52:15 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [01:03<13:08, 10.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples for up to 4 rounds, amounting to 18 attempts.\n",
      "Average Metric: 9.00 / 25 (36.0%): 100%|██████████| 25/25 [00:21<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:53:40 INFO dspy.evaluate.evaluate: Average Metric: 9 / 25 (36.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 10/80 [01:53<13:17, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples for up to 4 rounds, amounting to 30 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:27<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:56:01 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 13/80 [02:01<10:26,  9.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 13 examples for up to 4 rounds, amounting to 34 attempts.\n",
      "Average Metric: 12.00 / 25 (48.0%): 100%|██████████| 25/25 [00:21<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 12:58:24 INFO dspy.evaluate.evaluate: Average Metric: 12 / 25 (48.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0, 44.0, 48.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 19/80 [02:46<08:54,  8.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 9 full traces after 19 examples for up to 4 rounds, amounting to 49 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:20<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 13:01:31 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0, 44.0, 48.0, 40.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 7/80 [01:23<14:27, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples for up to 4 rounds, amounting to 22 attempts.\n",
      "Average Metric: 11.00 / 25 (44.0%): 100%|██████████| 25/25 [00:23<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 13:03:18 INFO dspy.evaluate.evaluate: Average Metric: 11 / 25 (44.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0, 44.0, 48.0, 40.0, 44.0]\n",
      "Best score so far: 56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/80 [00:42<18:12, 14.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 4 rounds, amounting to 9 attempts.\n",
      "Average Metric: 10.00 / 25 (40.0%): 100%|██████████| 25/25 [00:22<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/06 13:04:23 INFO dspy.evaluate.evaluate: Average Metric: 10 / 25 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores so far: [48.0, 52.0, 40.0, 40.0, 56.0, 44.0, 44.0, 44.0, 40.0, 48.0, 52.0, 36.0, 44.0, 44.0, 44.0, 44.0, 40.0, 36.0, 44.0, 48.0, 40.0, 44.0, 40.0]\n",
      "Best score so far: 56.0\n",
      "23 candidate programs found.\n",
      "Strategy 4 optimization completed!\n",
      "\n",
      "============================================================\n",
      "STRATEGY 4 - ENHANCED COT REASONING RESULTS:\n",
      "============================================================\n",
      "\n",
      "Predictor 1:\n",
      "Signature: StringSignature(question -> reasoning, answer\n",
      "    instructions='Answer Persian/Farsi questions using step-by-step reasoning. Break down multi-hop questions into logical steps.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring multi-step reasoning', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'desc': 'Step-by-step reasoning process in Persian', '__dspy_field_type': 'output', 'prefix': 'Reasoning:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Final precise Persian answer based on reasoning', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 8\n",
      "  Demo 1: بنیانگذار دستگاه کنونی آرایه‌شناختی پایه‌گذار چه چیز بود ؟...\n",
      "           -> علم طبقه‌بندی موجودات زنده\n",
      "  Demo 2: کدام یک از ملکه‌هایی که در برج سبز سر از پیکرشان جدا و گردن ...\n",
      "           -> آن بولین\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Strategy 4: Enhanced Chain-of-Thought Reasoning\n",
    "print(\"Strategy 4: Enhanced CoT Reasoning Optimization...\")\n",
    "\n",
    "# Create enhanced reasoning model\n",
    "mhqa_enhanced_reasoning_model = EnhancedPersianQAWithReasoningModule()\n",
    "\n",
    "# More intensive optimization for reasoning\n",
    "teleprompter_reasoning = dspy.BootstrapFewShotWithRandomSearch(\n",
    "    metric=enhanced_accuracy_metric,\n",
    "    max_bootstrapped_demos=10,   # More demos for reasoning\n",
    "    max_labeled_demos=8,\n",
    "    max_rounds=4,                # More rounds\n",
    "    num_candidate_programs=20,   # More candidates\n",
    "    num_threads=4\n",
    ")\n",
    "\n",
    "print(\"Optimizing enhanced reasoning model...\")\n",
    "mhqa_enhanced_reasoning_optimized = teleprompter_reasoning.compile(\n",
    "    mhqa_enhanced_reasoning_model,\n",
    "    trainset=mhqa_train_examples,\n",
    "    valset=mhqa_train_examples[:25]\n",
    ")\n",
    "\n",
    "print(\"Strategy 4 optimization completed!\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY 4 - ENHANCED COT REASONING RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "for i, predictor in enumerate(mhqa_enhanced_reasoning_optimized.predictors()):\n",
    "    print(f\"\\nPredictor {i+1}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(f\"Demonstrations: {len(predictor.demos)}\")\n",
    "        for j, demo in enumerate(predictor.demos[:2]):\n",
    "            print(f\"  Demo {j+1}: {demo.question[:60]}...\")\n",
    "            print(f\"           -> {demo.answer}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d154a18",
   "metadata": {},
   "source": [
    "# Comprehensive Evaluation\n",
    "\n",
    "Now we'll evaluate all four strategies and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_comprehensive(model, model_name, test_examples, max_examples=None):\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    if max_examples:\n",
    "        test_examples = test_examples[:max_examples]\n",
    "    \n",
    "    results = []\n",
    "    judge_lm = lm_reasoning\n",
    "    \n",
    "    # Track performance by answer type\n",
    "    type_performance = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
    "    \n",
    "    for example in tqdm(test_examples, desc=f\"Testing {model_name}\"):\n",
    "        try:\n",
    "            prediction = model(question=example.question)\n",
    "            model_answer = prediction.answer\n",
    "        except Exception as e:\n",
    "            model_answer = f\"Error: {e}\"\n",
    "        \n",
    "        is_correct = evaluate_answer_with_judge(\n",
    "            example.question,\n",
    "            example.answer, \n",
    "            model_answer,\n",
    "            judge_lm\n",
    "        )\n",
    "        \n",
    "        # Track by type\n",
    "        answer_type = getattr(example, 'answer_type', 'unknown')\n",
    "        type_performance[answer_type]['total'] += 1\n",
    "        if is_correct:\n",
    "            type_performance[answer_type]['correct'] += 1\n",
    "        \n",
    "        results.append({\n",
    "            'question': example.question,\n",
    "            'expected_answer': example.answer,\n",
    "            'model_answer': model_answer,\n",
    "            'clean_model_answer': clean_model_answer(model_answer),\n",
    "            'is_correct': is_correct,\n",
    "            'answer_type': answer_type,\n",
    "            'question_type': getattr(example, 'question_type', 'unknown')\n",
    "        })\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_correct = sum(1 for r in results if r['is_correct'])\n",
    "    total_questions = len(results)\n",
    "    accuracy = total_correct / total_questions if total_questions > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Overall Accuracy: {accuracy:.3f} ({total_correct}/{total_questions})\")\n",
    "    \n",
    "    print(f\"\\n  Performance by Answer Type:\")\n",
    "    for answer_type, perf in type_performance.items():\n",
    "        if perf['total'] > 0:\n",
    "            type_acc = perf['correct'] / perf['total']\n",
    "            print(f\"    {answer_type}: {type_acc:.3f} ({perf['correct']}/{perf['total']})\")\n",
    "    \n",
    "    return results, accuracy, type_performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b5727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MHQA EVALUATION - ALL STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "Evaluating Strategy 1: Enhanced BootstrapFewShot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Strategy 1: Enhanced BootstrapFewShot: 100%|██████████| 100/100 [04:03<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 1: Enhanced BootstrapFewShot Results:\n",
      "  Overall Accuracy: 0.490 (49/100)\n",
      "\n",
      "  Performance by Answer Type:\n",
      "    بلی/خیر: 0.762 (32/42)\n",
      "    شخص: 0.364 (4/11)\n",
      "    اسامی خاص دیگر: 0.167 (1/6)\n",
      "    مکان: 0.667 (2/3)\n",
      "    صفت: 0.000 (0/2)\n",
      "    کار هنری: 0.167 (1/6)\n",
      "    تاریخ: 0.167 (1/6)\n",
      "    گروه یا سازمان: 0.600 (6/10)\n",
      "    رویداد: 1.000 (1/1)\n",
      "    اسامی عام: 0.000 (0/10)\n",
      "    شماره: 0.333 (1/3)\n",
      "  Saved to: mhqa_dspy2_strategy_1_enhanced_bootstrapfewshot_results.csv\n",
      "\n",
      "Evaluating Strategy 2: Multi-Stage Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Strategy 2: Multi-Stage Processing: 100%|██████████| 100/100 [06:39<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 2: Multi-Stage Processing Results:\n",
      "  Overall Accuracy: 0.480 (48/100)\n",
      "\n",
      "  Performance by Answer Type:\n",
      "    بلی/خیر: 0.690 (29/42)\n",
      "    شخص: 0.364 (4/11)\n",
      "    اسامی خاص دیگر: 0.333 (2/6)\n",
      "    مکان: 0.667 (2/3)\n",
      "    صفت: 0.000 (0/2)\n",
      "    کار هنری: 0.500 (3/6)\n",
      "    تاریخ: 0.167 (1/6)\n",
      "    گروه یا سازمان: 0.600 (6/10)\n",
      "    رویداد: 0.000 (0/1)\n",
      "    اسامی عام: 0.000 (0/10)\n",
      "    شماره: 0.333 (1/3)\n",
      "  Saved to: mhqa_dspy2_strategy_2_multi-stage_processing_results.csv\n",
      "\n",
      "Evaluating Strategy 3: Ensemble Approach...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Strategy 3: Ensemble Approach: 100%|██████████| 100/100 [13:16<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 3: Ensemble Approach Results:\n",
      "  Overall Accuracy: 0.500 (50/100)\n",
      "\n",
      "  Performance by Answer Type:\n",
      "    بلی/خیر: 0.762 (32/42)\n",
      "    شخص: 0.273 (3/11)\n",
      "    اسامی خاص دیگر: 0.500 (3/6)\n",
      "    مکان: 1.000 (3/3)\n",
      "    صفت: 0.000 (0/2)\n",
      "    کار هنری: 0.167 (1/6)\n",
      "    تاریخ: 0.500 (3/6)\n",
      "    گروه یا سازمان: 0.500 (5/10)\n",
      "    رویداد: 0.000 (0/1)\n",
      "    اسامی عام: 0.000 (0/10)\n",
      "    شماره: 0.000 (0/3)\n",
      "  Saved to: mhqa_dspy2_strategy_3_ensemble_approach_results.csv\n",
      "\n",
      "Evaluating Strategy 4: Enhanced CoT Reasoning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing Strategy 4: Enhanced CoT Reasoning: 100%|██████████| 100/100 [06:40<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 4: Enhanced CoT Reasoning Results:\n",
      "  Overall Accuracy: 0.500 (50/100)\n",
      "\n",
      "  Performance by Answer Type:\n",
      "    بلی/خیر: 0.762 (32/42)\n",
      "    شخص: 0.364 (4/11)\n",
      "    اسامی خاص دیگر: 0.667 (4/6)\n",
      "    مکان: 0.667 (2/3)\n",
      "    صفت: 0.000 (0/2)\n",
      "    کار هنری: 0.167 (1/6)\n",
      "    تاریخ: 0.333 (2/6)\n",
      "    گروه یا سازمان: 0.500 (5/10)\n",
      "    رویداد: 0.000 (0/1)\n",
      "    اسامی عام: 0.000 (0/10)\n",
      "    شماره: 0.000 (0/3)\n",
      "  Saved to: mhqa_dspy2_strategy_4_enhanced_cot_reasoning_results.csv\n",
      "\n",
      "================================================================================\n",
      "FINAL MHQA COMPARISON:\n",
      "================================================================================\n",
      "0.500 - Strategy 3: Ensemble Approach\n",
      "0.500 - Strategy 4: Enhanced CoT Reasoning\n",
      "0.490 - Strategy 1: Enhanced BootstrapFewShot\n",
      "0.480 - Strategy 2: Multi-Stage Processing\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE MHQA EVALUATION - ALL STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use subset for faster evaluation and reduced costs\n",
    "eval_subset_size = 100  \n",
    "\n",
    "strategies = [\n",
    "    (mhqa_enhanced_optimized, \"Strategy 1: Enhanced BootstrapFewShot\"),\n",
    "    (mhqa_multistage_optimized, \"Strategy 2: Multi-Stage Processing\"),\n",
    "    (mhqa_ensemble_optimized, \"Strategy 3: Ensemble Approach\"),\n",
    "    (mhqa_enhanced_reasoning_optimized, \"Strategy 4: Enhanced CoT Reasoning\")\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "all_accuracies = {}\n",
    "\n",
    "for model, name in strategies:\n",
    "    results, accuracy, type_perf = evaluate_model_comprehensive(\n",
    "        model, name, mhqa_test_examples, max_examples=eval_subset_size\n",
    "    )\n",
    "    \n",
    "    all_results[name] = results\n",
    "    all_accuracies[name] = accuracy\n",
    "    \n",
    "    filename = f\"mhqa_dspy2_{name.lower().replace(' ', '_').replace(':', '')}_results.csv\"\n",
    "    pd.DataFrame(results).to_csv(filename, index=False)\n",
    "    print(f\"  Saved to: {filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MHQA COMPARISON:\")\n",
    "print(\"=\"*80)\n",
    "for name, accuracy in sorted(all_accuracies.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{accuracy:.3f} - {name}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7e2fa",
   "metadata": {},
   "source": [
    "# PQUAD Advanced Optimization\n",
    "\n",
    "Now let's apply the best performing strategy to PQUAD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQUAD Train examples: 50\n",
      "PQUAD Test examples: 100\n",
      "\n",
      "Applying best strategy to PQUAD: Strategy 3: Ensemble Approach\n",
      "Best MHQA accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "pquad_examples = prepare_enhanced_dspy_examples(pquad_data)\n",
    "pquad_train_examples = pquad_examples[:50]  # selected more compared to first notebook for better optimization\n",
    "pquad_test_examples = pquad_examples[50:]   \n",
    "\n",
    "print(f\"PQUAD Train examples: {len(pquad_train_examples)}\")\n",
    "print(f\"PQUAD Test examples: {len(pquad_test_examples)}\")\n",
    "\n",
    "# Determine best strategy from results\n",
    "best_strategy_name = max(all_accuracies.keys(), key=lambda k: all_accuracies[k])\n",
    "print(f\"\\nApplying best strategy to PQUAD: {best_strategy_name}\")\n",
    "print(f\"Best MHQA accuracy: {all_accuracies[best_strategy_name]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede5478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing PQUAD with Strategy 3: Ensemble Approach...\n",
      "Optimizing PQUAD model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [01:25<10:56, 14.91s/it]2025/09/06 13:44:22 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/09/06 13:44:22 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      " 14%|█▍        | 7/50 [01:51<13:18, 18.58s/it]2025/09/06 13:44:45 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/09/06 13:44:45 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      " 30%|███       | 15/50 [03:34<08:20, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 15 examples for up to 2 rounds, amounting to 26 attempts.\n",
      "PQUAD optimization completed!\n",
      "\n",
      "============================================================\n",
      "PQUAD OPTIMIZATION RESULTS (Strategy 3: Ensemble Approach):\n",
      "============================================================\n",
      "\n",
      "Predictor 1:\n",
      "Signature: EnhancedPersianQASignature(question -> answer\n",
      "    instructions='Answer Persian/Farsi questions with high accuracy. Focus on providing precise, concise answers that directly address the question. Consider Persian language nuances and cultural context.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring a factual answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Precise, concise Persian answer (one to three words when possible)', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 5\n",
      "\n",
      "Predictor 2:\n",
      "Signature: StringSignature(question -> reasoning, answer\n",
      "    instructions='Answer Persian/Farsi questions using step-by-step reasoning. Break down multi-hop questions into logical steps.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question requiring multi-step reasoning', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'desc': 'Step-by-step reasoning process in Persian', '__dspy_field_type': 'output', 'prefix': 'Reasoning:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Final precise Persian answer based on reasoning', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 5\n",
      "\n",
      "Predictor 3:\n",
      "Signature: PersianQAWithContextSignature(question -> question_type, key_entities, answer\n",
      "    instructions='Answer Persian questions by first analyzing the question type and required information.'\n",
      "    question = Field(annotation=str required=True json_schema_extra={'desc': 'Persian question to analyze and answer', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
      "    question_type = Field(annotation=str required=True json_schema_extra={'desc': 'Type of question (factual, comparison, temporal, etc.)', '__dspy_field_type': 'output', 'prefix': 'Question Type:'})\n",
      "    key_entities = Field(annotation=str required=True json_schema_extra={'desc': 'Key entities or concepts mentioned in the question', '__dspy_field_type': 'output', 'prefix': 'Key Entities:'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'Accurate Persian answer', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")\n",
      "Demonstrations: 5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply best strategy to PQUAD\n",
    "print(\"Optimizing PQUAD with Strategy 3: Ensemble Approach...\")\n",
    "\n",
    "pquad_model = EnsemblePersianQAModule()\n",
    "pquad_teleprompter = dspy.BootstrapFewShot(\n",
    "    metric=enhanced_accuracy_metric,\n",
    "    max_bootstrapped_demos=5,\n",
    "    max_labeled_demos=3,\n",
    "    max_rounds=2\n",
    ")\n",
    "\n",
    "print(\"Optimizing PQUAD model...\")\n",
    "if hasattr(pquad_teleprompter, 'num_candidate_programs'):  # BootstrapFewShotWithRandomSearch\n",
    "    pquad_optimized = pquad_teleprompter.compile(\n",
    "        pquad_model,\n",
    "        trainset=pquad_train_examples,\n",
    "        valset=pquad_train_examples[:15] if len(pquad_train_examples) > 15 else None\n",
    "    )\n",
    "else:  # Regular BootstrapFewShot\n",
    "    pquad_optimized = pquad_teleprompter.compile(\n",
    "        pquad_model,\n",
    "        trainset=pquad_train_examples\n",
    "    )\n",
    "\n",
    "print(\"PQUAD optimization completed!\")\n",
    "\n",
    "# Show PQUAD optimization results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"PQUAD OPTIMIZATION RESULTS ({best_strategy_name}):\")\n",
    "print(\"=\"*60)\n",
    "for i, predictor in enumerate(pquad_optimized.predictors()):\n",
    "    print(f\"\\nPredictor {i+1}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "    if hasattr(predictor, 'demos') and predictor.demos:\n",
    "        print(f\"Demonstrations: {len(predictor.demos)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PQUAD EVALUATION\n",
      "============================================================\n",
      "\n",
      "Evaluating PQUAD Strategy 3: Ensemble Approach...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing PQUAD Strategy 3: Ensemble Approach:   2%|▎         | 2/80 [00:16<10:28,  8.05s/it]2025/09/06 14:07:14 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:07:14 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  14%|█▍        | 11/80 [01:32<09:14,  8.03s/it]2025/09/06 14:08:30 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:08:30 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  29%|██▉       | 23/80 [03:19<07:49,  8.24s/it]2025/09/06 14:10:18 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:10:18 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  30%|███       | 24/80 [03:31<08:30,  9.12s/it]2025/09/06 14:10:29 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:10:29 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  39%|███▉      | 31/80 [04:34<06:53,  8.44s/it]2025/09/06 14:11:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:11:32 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:11:38 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:11:38 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/06 14:11:38 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:11:38 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/06 14:11:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:11:43 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  61%|██████▏   | 49/80 [07:21<04:17,  8.29s/it]2025/09/06 14:14:19 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:14:19 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:14:23 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:14:23 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  89%|████████▉ | 71/80 [10:59<01:21,  9.07s/it]2025/09/06 14:17:57 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:17:57 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  94%|█████████▍| 75/80 [11:37<00:45,  9.14s/it]2025/09/06 14:18:34 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:18:34 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:18:39 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:18:39 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach:  99%|█████████▉| 79/80 [12:15<00:08,  8.92s/it]2025/09/06 14:19:14 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "2025/09/06 14:19:14 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=300. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.1)  if the reason for truncation is repetition.\n",
      "Testing PQUAD Strategy 3: Ensemble Approach: 100%|██████████| 80/80 [12:26<00:00,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PQUAD Strategy 3: Ensemble Approach Results:\n",
      "  Overall Accuracy: 0.375 (30/80)\n",
      "\n",
      "  Performance by Answer Type:\n",
      "    unknown: 0.375 (30/80)\n",
      "\n",
      "PQUAD results saved to: pquad_dspy2_strategy_3_ensemble_approach_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PQUAD EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pquad_results, pquad_accuracy, pquad_type_perf = evaluate_model_comprehensive(\n",
    "    pquad_optimized, f\"PQUAD {best_strategy_name}\", pquad_test_examples, max_examples=80\n",
    ")\n",
    "\n",
    "# Save PQUAD results\n",
    "pquad_filename = f\"pquad_dspy2_{best_strategy_name.lower().replace(' ', '_').replace(':', '')}_results.csv\"\n",
    "pd.DataFrame(pquad_results).to_csv(pquad_filename, index=False)\n",
    "print(f\"\\nPQUAD results saved to: {pquad_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d70939",
   "metadata": {},
   "source": [
    "# Final Results Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbce25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL COMPREHENSIVE RESULTS - ADVANCED DSPY OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "MHQA Dataset Results (Top 4 Strategies):\n",
      "  1. 0.500 (+0.020) - Strategy 3: Ensemble Approach\n",
      "  2. 0.500 (+0.020) - Strategy 4: Enhanced CoT Reasoning\n",
      "  3. 0.490 (+0.010) - Strategy 1: Enhanced BootstrapFewShot\n",
      "  4. 0.480 - Strategy 2: Multi-Stage Processing\n",
      "\n",
      "PQUAD Dataset Results:\n",
      "  Best Strategy: 0.375 - Strategy 3: Ensemble Approach\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPREHENSIVE RESULTS - ADVANCED DSPY OPTIMIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nMHQA Dataset Results (Top {len(all_accuracies)} Strategies):\")\n",
    "for i, (name, accuracy) in enumerate(sorted(all_accuracies.items(), key=lambda x: x[1], reverse=True), 1):\n",
    "    improvement = \"\" if i == len(all_accuracies) else f\" (+{accuracy - min(all_accuracies.values()):.3f})\"\n",
    "    print(f\"  {i}. {accuracy:.3f}{improvement} - {name}\")\n",
    "\n",
    "print(f\"\\nPQUAD Dataset Results:\")\n",
    "print(f\"  Best Strategy: {pquad_accuracy:.3f} - {best_strategy_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52db4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE PREDICTIONS FROM BEST MODEL\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Q: آیا کاترین لانگفورد نقش دختر بچه نوجوانی که هانا بیکر نام داشت را در سریال ۱۳ دلیل برای اینکه بازی کرده است ؟\n",
      "Expected: بله\n",
      "Predicted: بله، کاترین لانگفورد نقش هانا بیکر را در سریال \"۱۳ دلیل برای اینکه\" بازی کرده است.\n",
      "Correct: True\n",
      "\n",
      "Example 2:\n",
      "Q: کدام یک از بازیگران فیلم اثر پروانه‌ای در فیلم آینه‌ها نیز ایفای نقش کرده است ؟\n",
      "Expected: ایمی اسمارت\n",
      "Predicted: آشتون کچر\n",
      "Correct: False\n",
      "\n",
      "Example 3:\n",
      "Q: کدام بازی ویدیویی شرکتی ژاپنی منبع الهام طراحی بازی سوپرتاکس بوده است ؟\n",
      "Expected: برادران سوپر ماریو\n",
      "Predicted: بازی سوپر ماریو\n",
      "Correct: True\n",
      "\n",
      "Example 4:\n",
      "Q: یکی از بازی های معروف شرکتی که اولین کنسول بازی ویدیویی خود را در سال ۱۹۹۷ توزیع کرد ؟\n",
      "Expected: برادران سوپر ماریو\n",
      "Predicted: سونی\n",
      "Correct: False\n",
      "\n",
      "Example 5:\n",
      "Q: آیا جایزه ای که سیدیبه در سال 2007 آن را دریافت کرد برای افرادی است که نقش مهمی در سینما داشته‌اند ؟\n",
      "Expected: بله\n",
      "Predicted: بله، جایزه‌ای که سیدیبه در سال 2007 دریافت کرد برای افرادی است که نقش مهمی در سینما داشته‌اند.\n",
      "Correct: True\n",
      "\n",
      "Example 5:\n",
      "Q: آیا جایزه ای که سیدیبه در سال 2007 آن را دریافت کرد برای افرادی است که نقش مهمی در سینما داشته‌اند ؟\n",
      "Expected: بله\n",
      "Predicted: بله، جایزه‌ای که سیدیبه در سال 2007 دریافت کرد برای افرادی است که نقش مهمی در سینما داشته‌اند.\n",
      "Correct: True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS FROM BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get best model\n",
    "best_model = None\n",
    "for model, name in strategies:\n",
    "    if name == best_strategy_name:\n",
    "        best_model = model\n",
    "        break\n",
    "\n",
    "if best_model:\n",
    "    sample_examples = mhqa_test_examples[:5]  \n",
    "    \n",
    "    for i, example in enumerate(sample_examples, 1):\n",
    "        try:\n",
    "            prediction = best_model(question=example.question)\n",
    "            model_answer = prediction.answer\n",
    "        except Exception as e:\n",
    "            model_answer = f\"Error: {e}\"\n",
    "        \n",
    "        print(f\"\\nExample {i}:\")\n",
    "        print(f\"Q: {example.question}\")\n",
    "        print(f\"Expected: {example.answer}\")\n",
    "        print(f\"Predicted: {clean_model_answer(model_answer)}\")\n",
    "        \n",
    "        is_correct = evaluate_answer_with_judge(\n",
    "            example.question, example.answer, model_answer, lm_reasoning\n",
    "        )\n",
    "        print(f\"Correct: {'True' if is_correct else 'False'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
